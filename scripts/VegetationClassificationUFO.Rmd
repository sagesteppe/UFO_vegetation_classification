---
title: "Vegetation Classification"
author: NULL
date: NULL
output:
  pdf_document: default
  word_document: default
always_allow_html: yes
header-includes:
- \usepackage[width=\textwidth]{caption}
- \usepackage{enumitem}
- \usepackage{wrapfig}
csl: ../citations/citations/apa.csl
bibliography: ../citations/citations/citations.bib
link-citations: yes
---

\pagenumbering{gobble}
\vspace{-1cm}

The original AIM sample design for the field office utilized stratified random sampling within classified vegetation types which the plots would make statistical inference to. The vegetation types were composed of alliances, communities, and associations, from the GAP-Landfire National Terrestrial Ecosystems spatial data set (@us2016gap). These units were aggregated, by an expert at the field office, to form broader vegetation groups which could have a greater number of replicates per stratum for statistical purposes. 

However, the GAP data set erroneously classifies many vegetation types at a non-negligible rate. Accordingly, many areas stratified as a certain vegetation type through the project did not, or seldom, featured the intended target vegetation. Several of the stratified sampling areas are in error, and while we cannot change the area associated with each plot, which was baked in at the original sample design over five years ago, in certain instances the actual stratum which the plot was sampled in, and the actual cover of that stratum across the landscape will be considered as necessary.

For example, of the nine vegetation types which our AIM project was stratified across, a couple were seldom seen, such as 'Mixed Conifer' vegetation. The study area does contain this vegetation type, however it represents only a fraction of a percent of the field office, and the designated stratified area seldom coincided with it's actual presence. As the mapped areas did not correlate with the vegetation type, neither could the random plots drawn within it. Accordingly the acreage of these areas should, in several instances, be considered within actual vegetation types, which the plots were sampled in, in order that these data are interpreted in the appropriate context. 

Additional problems were inherited with the vegetation types known as 'Other'. This is an aggregate developed from the *need* to classify the entirety of the field office. It functions as a catch-all designation for vegetation types which do not have adequate cover to form a broader stratification area and which have little semblance to other eight units. For example, a small patch of Blackbrush (*Coleogyne ramossisima*) on highway 90, gypsum terraces in the Paradox Valley, and escarpment vegetation with Stansbury's Cliffrose (*Purshia stansburyiana*) across the entire study area were placed into this designation. In hindsight as 'Other' is not a group wherein the members have any inherit similarities to themselves, we argue they should align with other groups which they share, even if only weak, affinities. Affinities between the gypsum terraces, to the salt desert, both soils which reduce the availability of free water for plant usage and result in barren to salt-tolerant vegetation are evident. Similarities between the escarpments of mesa's and the Pinyon-Juniper which occupies both the thin soil at the edges of the mesa, and the Pinyon-Juniper woodlands on the rocky soils at the toes of the escarpments, as well as those which are scattered throughout the Stansbury Cliffrose areas make this a tangible target for placement of these 'other' plots. 

A final problem is associated with the need to classify bodies of water. Our field office the 'Uncompahgre', is named after a word of Ute origin which has various translations, but a central element of them is a reference to 'Red Rocks' and 'flowing water'. Our design stratum had 4% of the survey area designated as riparian, in part to hold surface rivers. However, given the allowance to shift plots 50m in the cardinal directions, the tri-spoke design of AIM plots requiring a 60m diameter, and the deployment of Lotic AIM during the sampling period, few to none plots remained in the riparian vegetation type. Given that this is a significant amount of cover it is addressed here.

In order to resolve these issues with the analysis of the AIM 2017-2022 sample design, we reclassify the field office into four major, and one very minor, vegetation groups which may accommodate a major swath of the lands in the field office. To accomplish this we use over 1600 random points across the entire extent of the field office, classified in Google Earth, with National Aerial Imagery Program (NAIP) aerial imagery and a couple simple spatial data products, as inputs to a simple random forest model which is projected onto the aerial extent of the field office. 

```{r setup, include=FALSE}
knitr::opts_chunk$set(eval = F)
knitr::opts_chunk$set(echo = F)
knitr::opts_chunk$set(dpi = 300) 
knitr::opts_chunk$set(message = "hide")
knitr::opts_chunk$set(warning = "hide")
```

```{r Load Libraries, eval = T}
shhh <- suppressPackageStartupMessages
shhh(library(tidyverse))
shhh(library(terra))
shhh(library(sf))
shhh(library(here))
set.seed(72)

Mode <- function(x) {
  ux <- unique(x)
  ux[which.max(tabulate(match(x, ux)))]
}

strata_pal <- setNames(
  c('#4A5A28', '#ADB1B9', '#CEB88E', '#574039', '#B64841',
    '#1357a6', '#1B1212', '#F9E076', '#39993A', '#00688B'),
  c('PJ', 'SS', 'SD', 'MMS', 'AS', 'RI', 'OT', 'GR', 'PP', 'MC')
)
```

## Methods 

```{r Import and Subset AIM}

UFO_buffered <- st_read(
  paste0(here(), '/data/raw/BLM_CO_Administrative_Units/', 'admu_ofc_poly.shp'),
  quiet = T) %>% 
  filter(ADMU_NAME == 'UNCOMPAHGRE FIELD OFFICE') %>% 
 # st_buffer(32186) %>%  # buffer the FO by 20 miles
  st_transform(4269) %>% 
  dplyr::select(ADMU_NAME)

AIM_plots <- st_read('/media/sagesteppe/ExternalHD/aimDB/summaries/TerrADat.shp', quiet = T) %>% 
  dplyr::select(PrimaryKey:PlotID)
AIM_plots <- st_intersection(UFO_buffered,  AIM_plots) %>% 
  select(-ADMU_NAME)
PIntercept <- read.csv('/media/sagesteppe/ExternalHD/aimDB/PIntercept.txt')

plots <- left_join(AIM_plots, PIntercept, by = c('PrimaryKey' = 'PrimaryKey'))

rm(UFO_buffered)
```

NAIP Imagery from 2019 were downloaded from the official repository at 'Box' in Fall 2022. While decoding from MrSID (multiresolution seamless image database) to tif file formats, their resolution was reduced by a factor of four using the 'mrsiddecode' program (Vers. 9.5.1.4427) from LizardTech. This effectively reducing their resolution to 9.6 meters. Following decompression of MrSID data, all spatial data processing occurred using R version 4.2.1, and all computing performed on Linux Ubuntu (20 & 22) on multiple hardware. The NAIP raster tiles were united via mosaic, cropped to the extent of the Field Office's ownership, and masked to BLM administered surface areas. These data were then aligned with previously generated raster data sets derived from a 10 meter Digital Elevation Model (DEM); when required all re-sampling of these tiles were achieved using cubic spline interpolation.

```{bash NAIP imagery extraction and decoding, eval = F, echo = F}

sudo apt install libtbb-dev libgeos-dev
# install the binary into your home directory 
# http://bin.extensis.com/download/developer/MrSID_DSDK-9.5.1.4427-linux.x86-64.gcc48.tar.gz
# you can test that it now works using an example like:
./mrsiddecode -i infile.sid -o outfile.jpg

# it unfortunately requires that we extract the .sid files from the .zip files!!! 
cd /media/sagesteppe/ExternalHD/NAIP/raw_imagery/

for file in *zip; do

  in_path='/media/sagesteppe/ExternalHD/NAIP/raw_imagery/'
  out_path='/media/sagesteppe/ExternalHD/NAIP/decoded/'
  infilename="$in_path${file%.zip}/${file%.zip}.sid"
  outfilename="$out_path${file%.zip}.tif"
  
  mkdir ${file%.zip}
  unzip $file -d ${file%.zip}
  ~/MrSID_DSDK-9.5.1.4427-linux.x86-64.gcc48/Raster_DSDK/bin/mrsiddecode -i $infilename -o  $outfilename -s 4
  rm -r ${file%.zip} # reduce by  a factor of 4 from 60cm -> 120 -> 240 -> 960 and resample to align with DEM
  
  now=$(date)
  printf "${file%.zip} was processed at: $now\n"
  
done

```

```{r NAIP imagery processing}

# the first step is to verify that we have all relevant NAIP datasets - i.e. 
# those which intersect the land ownership of the office
UFO_land <- st_read(
  paste0(here(), '/data/processed/UFO_Allotments/', 'UFO_Allotments.shp'),
  quiet = T) %>% 
  st_transform(4269) %>% 
  st_union() %>% 
  st_cast('POLYGON') %>% 
  st_as_sf() %>% 
  st_make_valid()

target_counties <- tigris::counties(state = 'CO') %>% st_make_valid()
target_counties <- target_counties[st_intersection(target_counties, UFO_land),] %>% 
  dplyr::select(COUNTYFP, NAME) %>% 
  st_make_valid()

ggplot(UFO_land) +
  geom_sf( fill = 'black') +
  geom_sf(data = target_counties, fill = NA)

# verify that you have downloaded and processed all relevant county tiles. 
path <- '/media/sagesteppe/ExternalHD/NAIP/decoded'
dl_naip <- list.files(path, pattern = 'tif$')
dl_naip_tiles <- str_extract(dl_naip, '[a-z]{2}[0-9]{3}') %>% 
  str_remove(., '[a-z]{2}') %>% 
  unique()

# Load raster datasets
dl_naip <- file.path(path, dl_naip)
dl_naip_IR <- dl_naip[grep('1-1_hn_s', dl_naip)]
dl_naip_NC <- dl_naip[grep('1-1_hc_s', dl_naip)]

naip_imagery_IR <- lapply(dl_naip_IR, rast)
naip_imagery_NC <- lapply(dl_naip_NC, rast)

target_counties <- target_counties[match(dl_naip_tiles, target_counties$COUNTYFP),]
dl_naip_NC

names(naip_imagery_IR) <- target_counties$NAME
names(naip_imagery_NC) <- target_counties$NAME

# rm(dl_naip, path, dl_naip_IR, dl_naip_NC, target_counties, dl_naip_tiles)

# we need to transform the CRS of several rasters from UTM zone 13 to zone 12

UFO_extent_12 <- vect(st_transform(UFO_land, 26912))
UFO_extent_13 <- vect(st_transform(UFO_land, 26913))

for (i in c(1:2,5:6)){
  naip_imagery_NC[[i]] <- crop(naip_imagery_NC[[i]],  UFO_extent_13, mask = T) # reduce extent of files
}
for (i in c(3,4,7)){
  naip_imagery_NC[[i]] <- crop(naip_imagery_NC[[i]],  UFO_extent_12, mask = T)
}
for (i in c(1,5,2)){
  naip_imagery_NC[[i]] <- project(naip_imagery_NC[[i]],  y = naip_imagery_NC[[4]],
                              method = 'cubicspline', align = T, threads = 20)
}
naip_imagery_NC[[6]] <- project(naip_imagery_NC[[6]],  y = naip_imagery_NC[[5]],
                              method = 'cubicspline', align = T, threads = 20)

naip_imagery_collection_NC <- sprc(naip_imagery_NC) # make a wide raster of all tiles
UFO_NAIP_NC <- mosaic(naip_imagery_collection_NC) # create a single large product of rasters

plot(UFO_NAIP_NC)

path <- '/media/sagesteppe/ExternalHD/NAIP/'
# dir.create(file.path(path, 'processed'))
fname <- file.path(path, 'processed', 'NC_naip.tif')
#tile_borders <- rast(ncols = 2, nrows = 2, crs = crs(UFO_NAIP_NC), 
#                     xmin = xmin(UFO_NAIP_NC), xmax = xmax(UFO_NAIP_NC), 
#                     ymax = ymax(UFO_NAIP_NC), ymin = ymin(UFO_NAIP_NC))
#makeTiles(UFO_NAIP_NC, tile_borders, fname)
writeRaster(UFO_NAIP_NC, fname)

rm(naip_imagery_collection_IR, naip_imagery_collection_NC, naip_imagery_IR, naip_imagery_NC, i)
```


```{r Import processed NAIP imagery and resample to other products}
path <- '../../NAIP/processed'
files <- list.files(path)

naip_IR <- files[grep('IR_naip.tif', files)]
naip_NC <- files[grep('NC_naip.tif', files)]

naip_IR <- rast(file.path(path, naip_IR))
naip_NC <- rast(file.path(path, naip_NC))

# now we will resample this product so that it aligns with the existing physiographic products we have. 

dem <- rast(file.path( '../data/processed/',
            list.files(file.path('../data/processed'),
            pattern = "dem.*smooth.*tif$")))

naip_IR <- resample(naip_IR, dem, method = 'cubicspline', threads = 20, 
                    filename = file.path(path, 'IR_naip_resamp.tif'))
naip_NC <- resample(naip_NC, dem, method = 'cubicspline', threads = 20, 
                    filename = file.path(path, 'NC_naip_resamp.tif'))
```

```{r settings for texture band creation, eval = T}
stats <- c("mean", "variance", 'homogeneity', 'contrast', 'dissimilarity')
wind <- c(5, 5)
```


```{r Create Texture Raster band, eval = F}

library(factoextra)
library(FactoMineR)
library(glcm)
# https://zia207.github.io/geospatial-r-github.io/texture-analysis.html

# we will perform different runs on the natural color and IR bands to develop the GLCM

path <- '/media/reed/ExternalHD/NAIP/processed'
files <- list.files(path, pattern = 'resamp')

naip_IR_r <- raster::raster(file.path(path, files[grep('IR*', files)]))
naip_NC_r <- raster::raster(file.path(path, files[grep('NC*', files)]))

Sys.time()
glcm.red <- glcm::glcm(naip_IR_r,
                 window = wind, shift = list(c(0,1), c(1,1), c(1,0), c(1,-1)), 
                 statistics = stats, 
                 min_x = 1, max_x = 255, na_opt = 'ignore', na_val = 0)
Sys.time()

Sys.time()
glcm.colour <- glcm::glcm(naip_NC_r,
                 window = wind, shift = list(c(0,1), c(1,1), c(1,0), c(1,-1)), 
                 statistics = stats, 
                 min_x = 1, max_x = 255, na_opt = 'ignore', na_val = 0)
Sys.time()

writeRaster(glcm.colour, file.path(path, 'glcm_red_textures.tif'))
writeRaster(glcm.colour, file.path(path, 'glcm_colour_textures.tif'))

glcm.red <- rast(file.path(path, 'glcm_red_textures.tif'))
glcm.colour <- rast(file.path(path, 'glcm_colour_textures.tif'))

rm(naip_IR_r, naip_NC_r)

## we determine which bands contain the most variation using a PCA
all_textures <- c(glcm.red, glcm.colour)
all_textures <- scale(all_textures, center = T) # scale the data before the function
all_textures[is.na(all_textures)] <- 0 # define zero for all missing values

Sys.time()
texture_values <- values(spatSample(all_textures, # this can take up to an hour or so
                                    ((dim(all_textures)[1] * dim(all_textures)[2]) * 0.01), 
                        as.raster=TRUE))
Sys.time()
rf_veg_pca <- prcomp(texture_values)

saveRDS(rf_veg_pca, "../results/stats/veg_pca.rds")
rf_veg_pca <- readRDS("../results/stats/veg_pca.rds")
texture_PC <- predict(all_textures, rf_veg_pca)

fviz_pca_var(rf_veg_pca,
             col.var = "contrib", # Color by contributions to the PC
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE     # Avoid text overlapping
)

summary(rf_veg_pca)
rf_veg_pca[["rotation"]]

# now select and write out bands with considerable influence to variation
texture_PrincComponents <- subset(texture_PrincComponents, c(1:2))
names(texture_PrincComponents) <- paste0('principal_Component', 
                                         rep(1:dim(texture_PrincComponents)[3]))

plot(texture_PrincComponents)
texture_PrincComponents <- mask(texture_PrincComponents, glcm.red)
plot(texture_PrincComponents)

writeRaster(texture_PrincComponents, file.path(path, 'Textures_pca.tif'), overwrite = T)

rm(texture_PrincComponents, all_textures, glcm.red, glcm.colour, texture_values, rf_veg_pca, texture_PC, files, sr)
```

A Gray Level Co-occurrence Matrix (GLCM) was created using the 'glcm' package to create a texture raster layer to aid in classification (@haralick1973textural, @glcm). Texture bands are, among other properties, capable of indicating the amounts of heterogeneity of habitat types across the landscape. Texture layers were produced using both NAIP natural color and infrared imagery. Texture statistics: `r toString(paste0(stats))`, with windows of `r toString(wind[1])` in both direction, shifts in all directions (i.e. *Queen's case*), and the default value of 32 grey levels. NAIP data were processed to derive another preditive layer a Normalized Difference Vegetation Index (NDVI) band.
$$ NDVI = (NearIR - Red) / (NearIR + Red) $$
NDVI is well suited for identifying sparsely vegetated areas, it was useful in distinguishing salt desert from all other strata, and help in distinguishing between Mixed-Mountain Shrub and Pinyon-Juniper. 

```{r create NDVI band}
# (NIR - Red) / (NIR + Red)

naip_NC <- rast(naip_NC_r)
naip_IR <- rast(naip_IR_r)
rm(naip_IR_r, naip_NC_r)

naip_ndvi <- (naip_IR[[1]] - naip_NC[[1]]) / (naip_IR[[1]] + naip_NC[[1]])
plot(naip_ndvi) # see the green up at the boundaries with forest service.

writeRaster(naip_ndvi, file.path(path, 'NDVI.tif'), overwrite = T)
```

```{r Export Points for Manual Classification in Google Earth}

rndm_VegPts <- st_read(
  file.path(here(), '/data/processed/UFO_Allotments/', 'UFO_Allotments.shp'),
  quiet = T) %>%
  st_union() %>%
  vect()

rndm_VegPts <- rndm_VegPts
  spatSample(size = 150, method="random") %>%
  st_as_sf() %>%
  mutate(ID = 1:n()) %>%
  select(ID) %>%
  st_transform(4326) %>%
  as('Spatial')

rndm_VegPts2 <- rndm_VegPts %>%
  spatSample(size = 250, method="random") %>%
  st_as_sf() %>%
  mutate(ID = 1:n()) %>%
  select(ID) %>%
  st_transform(4326) %>%
  as('Spatial')
 
maptools::kmlPoints(rndm_VegPts, kmlfile = '../data/raw/UFO_Random_Veg_pts.kml',
          name = rndm_VegPts[['ID']], kmlname = 'Random_Veg_pts')
maptools::kmlPoints(rndm_VegPts2, kmlfile = '../data/raw/UFO_Random_Veg_pts2.kml',
          name = rndm_VegPts2[['ID']], kmlname = 'Random_Veg_pts2')

# we will also write a CSV for noting the results quickly.
rndm_VegPts <- rndm_VegPts %>%
  st_as_sf() %>%
  mutate('VegClass' = "",
    'Longitude' = st_coordinates(.)[,1],
    'Latitude' = st_coordinates(.)[,2]) %>%
  st_drop_geometry()
write.csv(rndm_VegPts, file = '../data/raw/UFO_Random_Veg_pts.csv' , row.names = F)
rndm_VegPts2 <- rndm_VegPts2 %>%
  st_as_sf() %>%
  mutate('VegClass' = "",
    'Longitude' = st_coordinates(.)[,1],
    'Latitude' = st_coordinates(.)[,2]) %>%
  st_drop_geometry()
write.csv(rndm_VegPts2, file = '../data/raw/UFO_Random_Veg_pts2.csv' , row.names = F)

rglr_VegPts <- rndm_VegPts %>%
  spatSample(size = 150, method="regular") %>%
  st_as_sf() %>%
  mutate(ID = 1:n()) %>%
  select(ID) %>%
  st_transform(4326) %>%
  as('Spatial')
 
maptools::kmlPoints(rglr_VegPts, kmlfile = '../data/raw/UFO_Regular_Veg_pts.kml',
          name = rglr_VegPts[['ID']], kmlname = 'Regular_Veg_pts')

# get some more. 
rglr_VegPts <- rndm_VegPts %>%
  spatSample(size = 750, method="regular") %>%
  st_as_sf() %>%
  mutate(ID = 1:n()) %>%
  select(ID) %>%
  st_transform(4326) %>%
  as('Spatial')

maptools::kmlPoints(rglr_VegPts, kmlfile = '../data/raw/UFO_Regular_Veg_pts2.kml',
          name = rglr_VegPts[['ID']], kmlname = 'Regular_Veg_pts2')

# we will also write a CSV for noting the results quickly.
rglr_VegPts <- rglr_VegPts %>%
  st_as_sf() %>%
  mutate('VegClass' = "",
    'Longitude' = st_coordinates(.)[,1],
    'Latitude' = st_coordinates(.)[,2]) %>%
  st_drop_geometry()
write.csv(rglr_VegPts, file = '../data/raw/UFO_Regular_Veg_pts2.csv' , row.names = F)


# we will also write out the 2022 plots to KML for manual classification. 
aim2022 <- st_read(file.path(here(), '/data/raw/AIM_Points_2022/', 'AIM_Points_2022.shp'),
        quiet = T) %>% 
  mutate(ID = 1:n()) %>%
  select(ID) %>%
  st_transform(4326) %>%
  as('Spatial')

maptools::kmlPoints(aim2022, kmlfile = '../data/raw/UFO_2022_AIM.kml',
          name = aim2022[['ID']], kmlname = 'UFO_2022_AIM')
aim2022 <- aim2022 %>%
  st_as_sf() %>%
  mutate('VegClass' = "",
    'Longitude' = st_coordinates(.)[,1],
    'Latitude' = st_coordinates(.)[,2]) %>%
  st_drop_geometry()
write.csv(aim2022, file = '../data/raw/UFO_2022_AIM.csv' , row.names = F)

rm(rndm_VegPts, rndm_VegPts2, aim2022)
```


```{r Read in classified points from GE and AIM, eval = T}
random <- file.path('../data/processed/',
  list.files('../data/processed/',  pattern = '*Random*'))
reg <- file.path('../data/processed/',
  list.files('../data/processed/',  pattern = '*Regular*'))

twenty22 <- read.csv('../data/processed/UFO_2022_AIM_CLASSIFIED.csv')
historicVeg <- read.csv('../data/processed/UFO_Veg_monitoring_CLASSIFIED.csv') %>% 
  mutate(across(where(is.character), ~ na_if(., "")))

plot_drawn <- (nrow(twenty22) + nrow(historicVeg))
plot_class <- bind_rows(twenty22, historicVeg) %>% drop_na()

reg_drawn <- do.call(rbind, lapply(reg, function(x) 
  read.csv(x, stringsAsFactors = FALSE)))
reg_pts <- reg_drawn %>% 
  drop_na() %>% 
  filter(VegClass %in% c('AS', 'MC', 'PJ', 'SD', 'SS', 'MMS'))

random_drawn <- do.call(rbind, lapply(random, function(x) 
  read.csv(x, stringsAsFactors = FALSE))) %>% 
  mutate(across(where(is.character), ~ na_if(., "")))
random_pts <- random_drawn %>% drop_na() 

rm(random, twenty22, historicVeg)
```

To create data set for training a random forest model, all `r toString(plot_drawn)` sampled AIM and LMF points, from 2018-2022, as well as all drawn 2022 AIM points, were exported to Google Earth and `r toString(nrow(plot_class))` were classified. `r toString(nrow(random_drawn))` random points were generated across the field office and `r toString(nrow(random_pts))` classified in Google Earth via the vegetation ecologist which lead the AIM sampling in 2022. An additional `r toString(nrow(reg_drawn))` regularly placed plots were drawn across the extent of the field office and `r toString(nrow(reg_pts))` were classified. Unclassified computer generated points were generally those that fell upon a wide road, or were outside BLM Ownership. Unclassified AIM/LMF points were LMF points which were the second closely located plot, but under distinct record elements in the TerraDat database. In all instances points were buffered by a 30m radius, to create the dimensions of an AIM plot, and the single most dominant vegetation type was recorded.

```{r buffer points from GE and AIM, eval = T}

p <- file.path(here::here(), 'data/processed')

reg_pts <-  reg_pts %>% 
  st_as_sf(coords = c("Longitude", "Latitude"), crs = 4326) %>% 
  mutate(Type = 'Regular', .after = 'ID') %>% 
  mutate(ID = as.character(ID)) %>% 
  st_transform(26912) %>% 
  st_buffer(30) 

random_pts <- random_pts %>% 
  st_as_sf(coords = c("Longitude", "Latitude"), crs = 4326) %>% 
  mutate(Type = 'Random2', .after = 'ID') %>% 
  st_transform(26912) %>% 
  st_buffer(30) %>% 
  mutate(ID = as.character(ID)) %>% 
  mutate(across(where(is.character), ~na_if(., ""))) %>%
  filter(VegClass %in% c('PJ', 'SD', 'SS', 'MMS'))

veg_pts <- plot_class %>% 
  st_as_sf(coords = c("Longitude", "Latitude"), crs = 4326) %>% 
  mutate(Type = 'Stratified', .after = 'ID') %>% 
  st_transform(26912) %>% 
  st_buffer(30) %>% 
  mutate(ID = as.character(ID))

# AIM DATA post K-Means is read in here
#veg_pts <- st_read(file.path(p, '/reclassified_AIM/reclassified_AIM.shp'), quiet = T) %>% 
#  st_transform(26912) %>%  # these alreday buffered by type. 
#  rename(ID = PlotKey, Type = Plot, VegClass = Veg_type) %>% 
#  bind_rows(., computer_pts) %>% 
#  drop_na() %>% 
#  vect()

# alt route use the manually classified
veg_pts <- bind_rows(veg_pts, random_pts, reg_pts) %>% 
  as(., "Spatial") %>% 
  vect()

rm(reg_pts, random_pts, plot_drawn, random_drawn, reg_drawn)
```

```{r Import all Geographic Data and extract occurrences to points}
# p <- '/media/sagesteppe/ExternalHD/plot_post_stratification'
UFO_land <- st_read(
  file.path('../../UFO_cartography',
            'BLM_CO_Surface_Management', 'BLM_CO_Surface_Management_Agency.shp'),
  quiet = T) %>% 
  st_transform(4269) %>% 
  st_union() %>% 
  st_cast('POLYGON') %>% 
  st_as_sf() %>% 
  st_make_valid() %>% 
  st_transform(26912) %>% 
  vect()


path <- '../../NAIP/processed'
files <- list.files(path)
files
naip_NC <- rast(file.path(
  path, files[grep('NC_naip_resamp.tif', files)]))
naip_IR <- rast(file.path(
  path, files[grep('IR_naip_resamp.tif', files)]))[[1]]
NDVI <- rast(file.path(
  path, files[grep('NDVI.tif', files)]))

texture <- rast(file.path(
  path, files[grep('Textures_pca.tif', files)]))
texture <- resample(texture, naip_NC, method = 'cubicspline')

PhysioPath <- '../../AIM_Field_rasters'

DEM <- rast(file.path(PhysioPath,
            list.files(PhysioPath,
            pattern = "dem.*smooth.*tif$")))
DEM <- crop(DEM,  UFO_land, mask = T)
DEM <- resample(DEM, naip_NC, method = 'cubicspline') 

slope <- rast(file.path(PhysioPath,
            list.files(PhysioPath,
            pattern = "slope*")))
slope <- terra::project(slope,  y = DEM, method = 'cubicspline', align = T)
slope <- crop(slope,  UFO_land, mask = T)
slope <- resample(slope, naip_NC, method = 'cubicspline') 

predictors <- c(naip_NC, naip_IR, NDVI, texture, DEM, slope)
names(predictors) <- c('NAIP_red', 'NAIP_green', 'NAIP_blue', 'NAIP_IR', 'NDVI', 
                       'GLCM_PC1', 'GLCM_PC2', 'DEM', 'Slope')
plot(predictors)

rm(naip_NC, texture, DEM, slope, PhysioPath, UFO_land, files, naip_IR, NDVI, path)
```

```{r set random forest model parameters proportion, eval = T}
train_prop <- 0.7
mTry <- 4
nTT <- 1000
sF <- 1.5
I <- 0.01
```

```{r Extract Predictor Variables to Points and create partitions, message = F, warning = 'hide'}
library(caret)
library(parallel)
library(doParallel)
library(randomForest)

veg_pts <- terra::project(veg_pts, terra::crs(predictors))
VegClass <- extract(predictors, veg_pts, method = 'simple', touches = F, fun = mean)#,
                  #  weights = T) # note weights work on Lightscape, but not parkland. 
VegClass <- cbind(as.data.frame(veg_pts), VegClass[,2:ncol(VegClass)])
VegClass <- VegClass[complete.cases(VegClass),]
VegClass <- cbind(VegClass[,4:ncol(VegClass)], 'class' = VegClass[,3])
VegClass$class <- as.factor(VegClass$class)

split_obs <- createDataPartition(VegClass$class,
                                 p = train_prop, # percentage of data as training
                                 list = FALSE)
train <- VegClass[split_obs,]
test <- VegClass[-split_obs,]

# here we gather a similar number of records to test the original stratification
# note we subset out the data which were drawn from the GAP data set. 

vp <- st_as_sf(veg_pts) %>%
  filter(Type != 'Stratified',
         VegClass %in% c('AS', 'MC', 'PJ', 'MMS', 'SD', 'SS')) %>% # only test on same vegclasses!!! 
  mutate(VegClass = as_factor(VegClass))
vp1 <- extract(predictors[[1]], vp, method = 'simple', fun = sum) 
vp1 <- vp1[complete.cases(vp1),] # ensure the regular plots are located in blm area for equal samples

vp <- rownames_to_column(vp, 'extractID') %>% 
  mutate(extractID = as.numeric(extractID)) %>% 
  right_join(., vp1, by = c('extractID' = 'ID'))

second_test <- ( 1 - (nrow(test) / nrow(vp) )) # select the same number of records
split_obs_strat <- createDataPartition(vp$VegClass,
                                 p = second_test, # percentage of data as training
                                 list = FALSE)
testOriginal <- vp[-split_obs_strat,]

mainDir <- '../data/processed/'
subDir <- 'StratTest'

# here we write these data out.
ifelse(!dir.exists(file.path(mainDir, subDir)), dir.create(file.path(mainDir, subDir)), FALSE)
# st_write(testOriginal, file.path(mainDir, subDir, 'TestSetStratification.shp'), quiet = T)
# write.csv(test, file.path(mainDir, 'rf_testing_data.csv'), row.names  = F)
# write.csv(train, file.path(mainDir, 'rf_training_data.csv'), row.names = F)

rm(VegClass, split_obs, testOriginal, vp, mainDir, subDir, testOriginal, split_obs_strat)
```


```{r import and prepare values for partition descriptions, eval = T}
train <- read.csv(file.path('../data/processed/', 'rf_training_data.csv')) %>% 
  select(class)

classes <- train %>% 
  count(class) %>% 
  mutate(values = paste0(class, "-", n)) %>% 
  pull(values)

test <- read.csv(file.path('../data/processed/', 'rf_testing_data.csv'))
```

To develop a random forest model, the data set of `r toString(nrow(veg_pts))` classified points were partitioned using a split of `r toString(train_prop)`:`r toString(1-train_prop)` for the training and testing sets (n = `r toString(nrow(train))`, n = `r toString(nrow(test))`) using 'caret' (@Caret). The data set was not balanced (number of plots per stratum:  `r toString(classes)`) due to the natural varying presence of these vegetation types in the study area.

```{r Fit Random Forest Model}

opt_mtry <- tuneRF(train, train$class, ntreeTry = nTT,
               stepFactor = sF, improve = I, trace = TRUE, plot = TRUE)

cl <- makeCluster(detectCores()-2)
registerDoParallel(cl)
veg_rf_model <- randomForest(class~., data=train, proximity=TRUE, 
                             ntree = nTT, mtry = 9)
stopCluster(cl); remove(cl)

saveRDS(veg_rf_model, file = paste0('../results/stats/RandomForest', Sys.Date(), '.rds'))

rm(cl, train, opt_mtry)
```

The number of mtry in the random forest model were tuned using the function 'tuneRF' with the number of try's set to `r toString(nTT)`, a step factor of `r toString(sF)` and a relative minimum improvement in Out of Bag (OOB) error rate set at `r toString(I)`. The random forest model was then trained using `r toString(mTry)` mtry and `r toString(nTT)` trees, all using the RandomForest package with parellel processing (@randomForest, @parallel, @doParallel). 

```{r Random Forest Results, results = 'hide', eval = T}

prds <- '../results/stats'
veg_rf_model <- readRDS(file = file.path(prds, 'RandomForest2022-10-31.rds'))
test$class <- as.factor(test$class)

data.frame(randomForest::importance(veg_rf_model, type = 2))# %>% # modifies in place!!! OOP :-) BUT assigned to deal with markdown.
#  rownames_to_column('Variable') %>% 
#  arrange(-MeanDecreaseGini) %>% # these results are to in the weeds
#  knitr::kable( col.names = c('Variable', 'Importance'),  align = "l", digits = 3,
#                caption = "Variable Importance in Random Forest Model")

# plot(veg_rf_model) # beyond the scope of the write-up
# generate a confusion matrix to determine accuracy on real data

test_prediction <- predict(veg_rf_model, test)
cmRestrat <- caret::confusionMatrix(test_prediction, test$class)

rm(test_prediction, train_prop, test, prds, classes)
```

```{r original GAP evaluation, eval = T}

p <- '../../UFO_AIM_Design_Stratification'
pts2test <- st_read('../data/processed/StratTest/TestSetStratification.shp', quiet = T) %>% vect()
gap <- rast('../../UFO_AIM_Design_Stratification/processed/UFO_Strata.tif')

pts2test <- project(pts2test, crs(gap))
reprocessedGAP <- read.csv(file.path(p, 'processed', 'UFO_strata_areas.csv')) %>% 
  select(RasterValue, Code, Cells)
factor_lvls <- c("AS", "MC", "MMS", "PJ", "SD", "SS", "RI", "OT", "GR", "PP" )

a <- extract(gap, pts2test, method = 'simple', touches = F)
a <- a[complete.cases(a),]

pts2test <- st_as_sf(pts2test) %>% 
  st_drop_geometry() %>% 
  select(VegClass) %>% 
  rowid_to_column('ID') 

mdsOrig <- a %>% 
  group_by(ID) %>% # these are the original values. 
  summarise(OriginalCover = Mode(BPS_CODE)) %>% 
  left_join(., pts2test, by = 'ID') %>% 
  left_join(., reprocessedGAP, by = c('OriginalCover' = 'RasterValue')) %>% 
  select(True = VegClass, Original = Code) %>% 
  mutate(across(.cols = everything(), ~ factor(.x, levels = factor_lvls)))

cmOrig <- caret::confusionMatrix(mdsOrig$True, mdsOrig$Original)

rm(factor_lvls, a, mdsOrig, gap)
```

```{r plot Results side by side, eval = F}

RestratDiagnostics <- data.frame(
  'Version' = rep('Original', length(rownames(cmRestrat[[4]]))),
  'Class' = gsub('Class: ', '', rownames(cmRestrat[[4]])),
  'Specificity' = cmRestrat[[4]][, grep('Specificity', colnames(cmRestrat[[4]])) ] ,
  'Sensitivity' = cmRestrat[[4]][, grep('Sens', colnames(cmRestrat[[4]])) ],
  'Accuracy' = cmRestrat[[4]][, grep('Bala', colnames(cmRestrat[[4]])) ]
)

OrigDiagnostics <- data.frame(
  'Version' = rep('Restratified', length(rownames(cmOrig[[4]]))),
  'Class' = gsub('Class: ', '', rownames(cmOrig[[4]])),
  'Specificity' = cmOrig[[4]][, grep('Specificity', colnames(cmOrig[[4]])) ] ,
  'Sensitivity' = cmOrig[[4]][, grep('Sens', colnames(cmOrig[[4]])) ],
  'Accuracy' = cmOrig[[4]][, grep('Bala', colnames(cmOrig[[4]])) ]
)

OrigDiagnostics <- filter(OrigDiagnostics, Class %in% RestratDiagnostics$Class)

dg <- bind_rows(RestratDiagnostics, OrigDiagnostics) %>% 
  filter(!Class %in% c('AS', 'MC')) %>% 
  mutate(Version = as_factor(Version))

strata_pal2 <- c(strata_pal, strata_pal)
strata_pal2 <- strata_pal2[match(dg$Class, names(strata_pal2))]
strata_pal2 <- strata_pal2[1:nrow(dg)]

shapes = c(18, 20)
shapes <- shapes[as.numeric(dg$Version)]

png('../results/figures/scatterplot.png')
par(mar = c(1.1, 3.1, 2.1, 3.1))
scatterplot3d::scatterplot3d(z = dg$Specificity, y = dg$Sensitivity, x = dg$Accuracy, type="h",
              pch = shapes, color = strata_pal2, cex.symbols = 2, box = F,las=1,
              zlab = 'Specificity', ylab = 'Sensitivity', xlab = 'Balanced Accuracy', 
              zlim  = c(0.5, 1), xlim  = c(0.5, 1), angle = 45, cex.axis = 0.6,
              main="Relationships between diagnostic\nmetrics for vegetation types")
dev.off()

rm(OrigDiagnostics, RestratDiagnostics, shapes, strata_pal2, dg, train)
```

Four simple diagnostic criteria were used to evaulate the predictions from out simple model.

$$ Sensitivity = \frac{\text{true positives}}{\text{true positives + false negatives }} $$
Which can be thought of as the probability of the method giving a positive result when the test subject is positive.

$$ Specificity = \frac{\text{true negatives}}{\text{true negatives + false positives }} $$
Which can be thought of as the probability of the method giving a negative result when the test subject is negative

$$ Accuracy = \frac{\text{correct classifications}}{\text{all classifications }} $$
Which can be thought of as the probability of the method giving the correct result under all conditions. *Balanced accuracy* accounts for differences in the number of individuals in groups, because if the number of individuals in groups differ widely, accuracy may gave a false indication of the models performance. This happens when one group, with many records, is classified very well at the expense of other groups. 

$$ kappa = \frac{\text{observed agreement} - \text{chance agreement}}{1 - \text{chance agreement}} $$ 

For our model the overall accuracy was `r toString(round(cmRestrat[["overall"]][["Accuracy"]],3))` (range `r toString(round(cmRestrat[["overall"]][["AccuracyLower"]],2))` - `r toString(round(cmRestrat[["overall"]][["AccuracyUpper"]], 2))` 95 % confidence interval), due to an imbalance in the number of observations per group a more appropriate for evaluating the overall performance of the model, is the kappa, `r toString(round(cmRestrat[["overall"]][["Kappa"]], 3))`, which indicates substantial agreement.

\begin{wrapfigure}{r}{0.45\textwidth}
  \centering
    \includegraphics[width=0.45\textwidth]{../results/figures/scatterplot.png}
  \caption{Three dimensional scatter-plot showing the relationship between three common metrics for evaluating the predictions of models. Circles represent the performance of the original stratification, and diamonds the new classification. Positions towards the upper right corner indicate more desirable qualities.}
\end{wrapfigure}

Notably, the model has high rates of Specificity (median = `r toString(round(median(cmRestrat[[4]][3:6, grep('Spec', colnames(cmRestrat[[4]]))]), 2))`, less Aspen and Mixed-Conifer), showing that when it predicts a vegetation type onto a pixel cell, the prediction is almost always correct; less so for prediction of Pinyon-Juniper (`r toString(round(cmRestrat[[4]][grep('PJ', rownames(cmRestrat[['byClass']])) , grep('Spec', colnames(cmRestrat[[4]])) ], 3))`). However, the model suffers from low Sensitivity (median = `r toString(round(median(cmRestrat[[4]][3:6, grep('Sens', colnames(cmRestrat[[4]]))]), 2))`, less AS and MC), indicating that it is unable to detect all occurrences of a vegetation type. For example, the model is only able to appropriately classify half of the occurrences of Sage Steppe (`r toString(round(cmRestrat[[4]][grep('SS', rownames(cmRestrat[['byClass']])) , grep('Sens', colnames(cmRestrat[[4]])) ], 3))`
) and Mixed Mountain Shrub (`r toString(round(cmRestrat[[4]][grep('MMS', rownames(cmRestrat[['byClass']]) ,'MMS') , grep('Sens', colnames(cmRestrat[[4]])) ], 3))`). Accordingly this model is susceptible to over-predicting the occurrence of Pinyon-Juniper, at the expense of Mixed Mountain Shrub and Sagebrush-steppe. This is to be expected given the sample imbalance, which contained many more plots PJ than other types. However numerous trials of reducing the number of Pinyon-Juniper plots did not significantly increase the quality of predictions. 

Further indicating, that the features used are not adequate for distinguishing between the transitional points where both Sagebrush-steppe phases into Pinyon-Juniper, and where shrubs increase in Pinyon-Juniper and it phases into Mixed-Mountain Shrub. In part we suspect this is an issue of the difficulty in splitting hairs required to generate the training data sets, and regrowth of historic vegetation in fire scars. While we believe this may be readily accomplished, given the objectives and goals of this process, we believe these are out of the current scope. 

In order to determine the relative performance of our model to the original GAP classification a confusion matrix was also generated. A similar number of test points, `r toString(nrow(pts2test))`, were used for both data sets. These points were only selected from the computer generated points in order to be independent of the data product, which the AIM plots were derived from. Several metrics indicate the original model is less accurate than the second model. The accuracy of the original model was `r toString(round(cmOrig[["overall"]][["Accuracy"]],3))` (range `r toString(round(cmOrig[["overall"]][["AccuracyLower"]],2))` - `r toString(round(cmOrig[["overall"]][["AccuracyUpper"]], 2))` 95% confidence interval), a difference of roughly `r toString(round(cmRestrat[["overall"]][["Accuracy"]] - cmOrig[["overall"]][["Accuracy"]],2))` to the new world. This test data set was also unbalanced and it's kappa, `r toString(round(cmOrig[["overall"]][["Kappa"]], 3))`, serves as a better predictor or overall model performance in this case, a difference of roughly `r toString(round(cmRestrat[["overall"]][["Kappa"]] - cmOrig[["overall"]][["Kappa"]], 2))`. Considering only the four major vegetation classes also present in the re-stratified model the original has similar rates of specificity (median = `r toString(round(median(cmOrig[[4]][3:6, grep('Spec', colnames(cmOrig[[4]]))]), 2))`, less AS and MC), but similar to the re stratified model but has lower rates of sensitivity (median = `r toString(round(median(cmOrig[[4]][3:6, grep('Sens', colnames(cmOrig[[4]]))]), 2))`, less AS and MC) (Figure 1). 

On the whole the new model outperforms the older model in all comparisons except for that the sensitivity of the original PJ classification is higher than that of the secondary PJ classification (`r toString(round(cmOrig[[4]][grep('PJ', rownames(cmOrig[['byClass']])) , grep('Sens', colnames(cmOrig[[4]])) ], 3))` to `r toString(round(cmRestrat[[4]][grep('PJ', rownames(cmRestrat[['byClass']])) , grep('Sens', colnames(cmRestrat[[4]])) ], 3))`) (Figure 1). In general their are multiple trade offs in the comparison of models, however the new model is both likely to correctly identify a the strata of a location, and to identify it correctly. 

```{r remove writing parameters, echo = F, warning = F}
rm(mTry, nTT, I, sF, pts2test)
```

```{r Predict random forest onto raster and smooth it, eval = F}

# predict model onto raster
predict_rf <- terra::predict(object = predictors, model = veg_rf_model, cpkgs = 'randomForest',
                     filename = file.path(p, '/PredictedVegClass.tif'),
                     overwrite = T)

# smooth the raster using focal statistics, we will find the mode in a rolling 
# window and re-assign values based upon that. 
predict_rf_smooth <- focal(predict_rf, w = 5, fun = modal, na.policy= 'omit')
plot(predict_rf_smooth, col = c('#e41a1c', '#377eb8', '#4daf4a', '#984ea3', '#ff7f00','#ffff33'))

predict_rf <- writeRaster(predict_rf_smooth,
                          file.path('../data/processed/PredictedVegClass-sm.tif'), overwrite = T)

rm(veg_rf_model)
```

## Comparison of Old and New Vegetation Models 

\begin{wrapfigure}{r}{0.35\textwidth}
  \centering
    \includegraphics[width=0.35\textwidth]{../results/figures/Stratum_cover.png}
  \caption{Changes in Predicted Land Cover}
\end{wrapfigure}

The initial sample design only classified around 41% of the field office as Pinyon-Juniper. Based on our field experiences we believe this is a serious underestimate. Despite the need to incorporate several extra - or 'Other' vegetation types into Pinyon-Juniper to fit the four model vegetation classification, manual classification resulted in 60% of the 1600 points being categorized as Pinyon-Juniper. This result is much more in line with our observations, and expectations. That smaller amounts of land were categorized as Pinyon-Juniper by the initial strata actually had large affects on plot placements. Because these woodlands were intended to be sampled at a lower rate than other strata, this roughly 20% of area which is PJ, but missed in the original stratification was sampled more than intended. Thus resulting in lower amounts of information on other vegetation types, such as sagebrush, which we wanted to know more about. Our model was slightly greedy with it's classification of Pinon-Juniper, raising it to 62% of the total area. An important caveat with our use of the models here is that, these areas include many late successional areas, which have not had disturbances to maintain their phases in mixed grasslands. 

Estimates of the amount of Sagebrush habitat differed widely between stratification efforts. In our experience many areas which were classified as Sagebrush in the original classification were actually Pinyon-Juniper, and the age of the Pinyon-Juniper was great enough that this was unlikely to be a result of the different ages of aerial imagery utilized by both models. The original stratification had roughly 25% of the entire field office classified as Sagebrush, this value was too high. Our manual classification resulted in 12% of the field office being classified as Sagebrush, and our final classification from the model resulted in only 9% of land being classified as Sagebrush. We feel the true value is closer to 12% than the 9% predicted by the model. As mentioned, not as many plots were included in this strata as desired, due to the classification accuracy, rather many of the plots in this strata ended up being Pinyon-Juniper. Classifying sagebrush was difficult for us due to areas where it transitions into Mixed-Mountain Shrub and Pinyon-Juniper, i.e. what constitutes the transition point between these? Theoretically only small amounts of these two types are required to convert a land, and given Sage grouse preferences these make sense for our purposes.

The amount of Salt Desert is similar between all three methods, they agree the amount of salt desert in the field office is around 15% - 18%. In general, these predictions aligned well, and plots classified as salt-desert were. 

A notable incongruence is present with Mixed-Mountain Shrub between the systems. The original classification predicted very modest amounts of this stratum throughout the area, and predicted relatively high amounts of other forest types. Our manual classification, which retained Aspen and Mixed Conifer forest, detected nearly twice as much of this strata in the field office. The modelled cover was slightly less than this, and likely closer to a true value where 10% of the field office is Mixed-Mountain Shrub.

\begin{wrapfigure}{r}{0.5\textwidth}
  \centering
    \includegraphics[width=0.5\textwidth]{../results/figures/circular_plot.png}
  \caption{Depiction of how raster cells in the UFO are redistributed from the original sample design (lower half), to the the reclassified spatial product for the sample design (upper half)}
\end{wrapfigure}

The relationships for the six remaining minor components is more complex, as is illustrated in Figure 3. This figure tracks the movement of each individual raster cell (or 'pixel') from the old to the new classification. As previously mentioned, the accuracy of the old system cannot be officially compared, but only discussed, because we reduced our classification process to the four major and two minor strata. For example, the original classification (lower half of circle), was correct in it's identification of Pinyon-Juniper, however it was unable to detect all of it. Hence the green line tracking from the bottom to the top, contains nearly every single pixel, except for a few which we were able to identify as Mixed-Mountain Shrub. Nearly all 4% of the Riparian stratum can be accommodated in Pinyon Juniper or the Salt desert stratum. This is sensible as nearly all ephemeral rocky canyon bottoms support Pinyon Juniper vegetation, and as the streams flow through the lower elevation portions of the field office, the riparian band is only a meter or two wide, and hence what an AIM crew would sample is Salt Desert.  Most of the original Mixed Conifer was re-assigned as Mixed-Mountain Shrub, with only a portion remaining in this stratum. Similarly, it appears roughly half of the Ponderosa Pine was assigned to Pinyon-Juniper and the other to Mixed-Mountain Shrub. Roughly half of the area classified as Aspen was maintained, and the other half was also reclassified as Mixed-Mountain Shrub. Most of the grassland stratum was transferred to Salt Desert

```{r prep graphics, echo = F, eval = T}

library(waffle)
library(tidyverse)
library(cowplot)

# original land cover of sample design

p <- '../../UFO_AIM_Design_Stratification'
initialGAP <- read.csv(file.path(p, 'raw', 'lookupTable.txt'))

reprocessedGAP <- reprocessedGAP %>% 
  mutate(Percent = round((Cells/sum(Cells) ) *100)) %>% 
  arrange(-Percent)

strata_pal <- strata_pal[order(match(names(strata_pal), reprocessedGAP$Code))]

strata_waffle <- reprocessedGAP %>% 
  mutate(Code = factor(Code, levels = names(strata_pal))) %>% 
  
  ggplot(., aes(fill = factor(Code), values = Percent)) + 
  geom_waffle(color = 'white') + 
  scale_fill_manual(name = 'Statum',
                    values = strata_pal, 
                    labels = names(strata_pal)) + 
  coord_equal() + 
  theme_void() + 
  labs(title = 'initial stratification')  +
  guides(fill=guide_legend(ncol=2)) +
  theme(plot.title = element_text(hjust = 0.5), 
        legend.title.align = 0.5,
        plot.margin = unit(c(0.0,0.0,0.0,0.0), "lines"))

legend <- get_legend(strata_waffle)
strata_waffle <- strata_waffle + theme(legend.position='none')

# now a waffle of what percent habitat plots were located actually IN ??

veg_pts <- veg_pts %>% 
  st_as_sf() %>% 
  st_drop_geometry() %>% 
  filter(Type != 'Stratified') %>% 
  group_by(VegClass) %>% 
  count() %>% 
  ungroup() %>% 
  mutate(Percent = round((n/sum(n))*100 ))  %>% 
  arrange(-Percent)

strata_pal <- strata_pal[order(match(names(strata_pal),veg_pts$VegClass))]
strata_pal3 <- strata_pal[1:nrow(veg_pts)]

random_waffle <- ggplot(veg_pts, aes(fill = VegClass, values = Percent)) + 
  geom_waffle(color = 'white') + 
  scale_fill_manual(name = 'Statum',
                    values = strata_pal3, 
                    labels = names(strata_pal3)) + 
  coord_equal() + 
  theme_void() + 
  theme(legend.position="none") +
  labs(title = 'human classification')  +
  theme(plot.title = element_text(hjust = 0.5),
        plot.margin = unit(c(0.0,0.0,0.0,0.0), "lines"))

#  a waffle of what percent habitats exist in UFO based on reclassification

reclassified <- rast('../../plot_post_stratification/data/processed/PredictedVegClass.tif')

#plot(reclassified, col = c('#e41a1c', '#377eb8', '#4daf4a', '#984ea3', '#ff7f00','#ffff33'))
area <- values(reclassified)
area <- area[!is.na(area)] # 4 SS, # 3 SD, 2 PJ, 1 MMS
area <- aggregate(area, list(num=area), length)

ltable <- data.frame(
  num = c(1, 2, 3, 4, 5, 6), 
  Stratum = c('AS', 'MC', 'MMS', 'PJ', 'SD', 'SS')
) 

```

```{r create strata, eval = F}

vegclass <- area %>% 
  inner_join(., ltable, 
            by = 'num') %>% 
  select(Cells = x, RasterValue = num, Stratum) %>% 
  mutate(Percent = round((Cells/sum(Cells) ) *100)) %>% 
  arrange(-Percent)

strata_pal <- strata_pal[order(match(names(strata_pal),vegclass$Code))]
strata_pal2 <- strata_pal[1:nrow(vegclass)]

reclass_waffle <- ggplot(vegclass, aes(fill = Stratum, values = Percent)) + 
  geom_waffle(color = 'white') + 
  scale_fill_manual(name = 'Statum',
                    values = strata_pal2, 
                    labels = names(strata_pal2)) + 
  coord_equal() + 
  theme_void() + 
  theme(legend.position="none") + 
  labs(title = 're-modeled classification')  +
  theme(plot.title = element_text(hjust = 0.5),
        plot.margin = unit(c(0.0,0.0,0.0,0.0), "lines"))

plot_col <- plot_grid(strata_waffle, random_waffle,
                      reclass_waffle, legend, ncol = 1, rel_widths = c(1,1,1,1),
                      rel_heights = c(1,1,1,1))

title <- ggdraw() + 
  draw_label("Percent Land Cover",
    fontface = 'bold') 

p <- plot_grid(
  title, plot_col,
  ncol = 1,
  rel_heights = c(0.05, 1) )

png('../results/figures/Stratum_cover.png')
p
dev.off()

```

```{r clean some variables}
rm(strata_pal2, strata_pal3, random_waffle, reclass_waffle, legend, plot_col, strata_waffle, title, p)
```

```{r}
reclassified <- rast('../data/processed/PredictedVegClass.tif')
d <- cellSize(reclassified)

area <- values(reclassified)
area <- area[!is.na(area)] # 4 SS, # 3 SD, 2 PJ, 1 MMS
area <- aggregate(area, list(num=area), length)

sum(values(d), na.rm = T)
sum(area$x) * 0.01989198
plot(d)

3922577634 * 0.0002471054

(600000 + 600000 + 960000) / 1000000
```

```{r compare values between rasters to create flow chart, eval = F}
# first match the resolutions of these products, we will re sample the coarser original
# to the finer remapped classification. 
p <- '../../UFO_AIM_Design_Stratification'
original_strat <- rast(file.path(p, 'processed', 'UFO_Strata.tif'))
rm(original_strat)

area <- values(original_strat)
area <- area[!is.na(area)] 
area <- aggregate(area, list(num=area), length)
area <- area %>% 
  inner_join(., reprocessedGAP %>% select(RasterValue, Code), 
            by = c('num' = 'RasterValue')) %>% 
  rename(Cells = x)

# probably dont try the following on gov't computer, reach out to reed (sagesteppe) and he can run it
r <- rast(list(original_strat, reclassified))
rvals <- as.matrix(r, na.rm = T)
rvals <- rvals[complete.cases(rvals),]
rvals <- data.frame(rvals) %>% 
  group_by(lyr1) %>% 
  count(BPS_CODE) %>% 
  rename(Reclassified = lyr1,
        Original= BPS_CODE)

p1 <- '../data/processed'
write.csv(rvals, file.path(p1, 'Extracted_raster_values.csv'), row.names = F)
write.csv(area, file.path(p1, 'Count_OriginalStrat_raster_values.csv'), row.names = F)
rm(d, original_strat, reclassified)
```

```{r reimport data for showing flow from veg classes, echo = F, eval = F}

shhh(library(circlize))

p1 <- '../../plot_post_stratification/data/processed'
rvals <- read.csv(file.path(p1, 'Extracted_raster_values.csv'))
area <- read.csv(file.path(p1, 'Count_OriginalStrat_raster_values.csv'))

rvals <- rvals %>% 
  mutate(n = (n/sum(n))*100) %>% 
  pivot_wider(names_from = 'Reclassified', values_from = 'n') %>% 
  column_to_rownames('Original') %>% # for circle chart. 
  as.matrix()

colnames(rvals) <- paste0(' ', ltable$Stratum)
rownames(rvals) <- reprocessedGAP %>% 
  arrange(RasterValue) %>% 
  pull(Code)

colOrder <- c(" AS", " MMS"," PJ"," MC"," SD", " SS")
rowOrder <- c('AS', 'MMS', 'GR', 'PJ', 'PP', 'RI', 'SS', 'MC', 'SD', 'OT')
rvals <- rvals[ rowOrder, colOrder]

sp2 <- strata_pal # create a palette to mark the colors in both ends
names(sp2) <- paste0(' ', names(strata_pal))
all_pals<- c(strata_pal, sp2)

# let us consider removing the labels, and adding a legend for the colors instead. 

png('../results/figures/circular_plot.png')
par(mar = c(1.5, 1.5, 4.1, 1.5))
circos.par(start.degree = 0)
chordDiagram(rvals, transparency = 0.5, directional = 1, 
             grid.col = all_pals, diffHeight  = -0.04, 
             big.gap = 10,
             annotationTrackHeight = c(0.10, 0.10))
abline(h = 0, lty = 2, col = "#000000")
title("Movement of Pixels from stratification\n(bottom) to post stratification (top)")
circos.clear()
dev.off()

```


# References

\small
