---
title: "Vegetation_Classification"
author: "steppe"
date: "2022-10-03"
output:
  word_document: default
  html_document: default
---

The initial AIM sample design for a field office utilized stratified random sampling within classified vegetation types which the plots could make inference to. The vegetation types were composed of alliances and communities from the GAP-Landfire National Terrestrial Ecosystems spatial data set (PUBLISHER 2011). Alliances and communities were aggregated, by an expert at each field office, to form broader vegetation groups in order for them to have more samples per unit area.

However, the GAP data set erroneously classifies many vegetation types at a non-negligible rate. Accordingly, a number of areas stratified as one vegetation type through the project may not feature the intended target vegetation. Thus, several of the stratified zones are in error, and may sensibly have their plots and acreage reallocated to inform inference of conditions in the larger vegetation types. 

For example, of the nine vegetation types which the AIM project was stratified across, a couple were seldom seen, such as 'Mixed Conifer' vegetation. The study area does contain this vegetation type, however it represents a fraction of a percent in the Field Office, and the designated stratified area did not coincide with it's actual presence. As the stratified area did not correlate with the vegetation type, neither could the random plots drawn within it. Accordingly the acreage of these areas should be reclassified into their appropriate vegetation types, alongside the plot, in order that these data are interpreted in the correct context. 

Additional problems were inherited with a vegetation types known as 'Other'. This is an aggregate developed from the *need* to classify the entirety of the field office. It functions as a catch-all designation for vegetation types which do not have adequate cover to form a broader classification. For example, a small patch of Blackbrush (*Coleogyne ramossisima*) on 90, gypsum terraces in the Paradox Valley, and escarpment vegetation with Stansbury's Cliffrose (*Purshia stansburyiana*) across the entire study area were placed into this designation. As 'Other' is not a group wherein the members have any inherit similarities to themselves, we argue they should align with other groups which they share, even if only weak, affinities. Affinities between the gysum terraces, to the salt desert, both soils which reduce the availability of free water for plant usage and result in barren to salt-tolerant vegetation are evident. Similarities between the escarpments of mesa's and the Pinyon-Juniper which occupies both the thin soil at the edges of the mesa, and the Pinyon-Juniper woodlands on the rocky soils at the toes of the escarpments, as well as are scattered throughout the Stansbury Cliffrose areas make this a tangible target for placement of these 'other' plots. 

A final problem is associated with the need to classify bodies of water. Our field office the 'Uncompahgre', is named after a word of Ute origin which has various translations, but a central element of them is a reference to 'Red Rocks' and 'flowing water'. Our design stratum had 4% of the survey area designated as riparian, in part to hold surface rivers. However, given the allowance to shift plots 50m in the cardinal directions, the tri-spoke design of aim plots requiring a 60m diameter, and the deployment of Lotic AIM during the sampling period, few to none plots remained in the riparian vegetation type. 

In order to resolve these issues with the analysis of the AIM 2017-2022 sample design, we reclassify the field office into four major, and one very minor, vegetation groups which may accommodate a major swath of the lands in the field office to make inference too. To accomplish this we use over 1600 random points across the entire extent of the field office, classified in Google Earth, NAIP aerial imagery and a couple simple spatial data products, as inputs to a simple random forest model which is projected onto the aerial extent of the field office. 

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F)
knitr::opts_chunk$set(message = "hide")
knitr::opts_chunk$set(warning = "hide")
```

```{r Load Libraries, message = F ,warning = F}
shhh <- suppressPackageStartupMessages
shhh(library(tidyverse))
shhh(library(terra))
shhh(library(sf))
shhh(library(here))
set.seed(72)

Mode <- function(x) {
  ux <- unique(x)
  ux[which.max(tabulate(match(x, ux)))]
}
```

# Methods 

```{r Import and Subset AIM, echo = F, eval = F}

UFO_buffered <- st_read(
  paste0(here(), '/data/raw/BLM_CO_Administrative_Units/', 'admu_ofc_poly.shp'),
  quiet = T) %>% 
  filter(ADMU_NAME == 'UNCOMPAHGRE FIELD OFFICE') %>% 
 # st_buffer(32186) %>%  # buffer the FO by 20 miles
  st_transform(4269) %>% 
  dplyr::select(ADMU_NAME)

AIM_plots <- st_read('/media/sagesteppe/ExternalHD/aimDB/summaries/TerrADat.shp', quiet = T) %>% 
  dplyr::select(PrimaryKey:PlotID)
AIM_plots <- st_intersection(UFO_buffered,  AIM_plots) %>% 
  select(-ADMU_NAME)
PIntercept <- read.csv('/media/sagesteppe/ExternalHD/aimDB/PIntercept.txt')

plots <- left_join(AIM_plots, PIntercept, by = c('PrimaryKey' = 'PrimaryKey'))

rm(UFO_buffered)
```

Colorado 2019 NAIP Imagery were downloaded from the official repository at Box in Fall 2022. While decoding from MrSID to tif file formats, their resolution was reduced by a factor of four using the 'mrsiddecode' program (Vers. 9.5.1.4427) from LizardTech. This effectively reducing their resolution to 9.6 meters. Following decompression of MrSID data, all spatial data processing occurred using R version 4.2.1, all computing performed on linux Ubuntu (20 & 22) on multiple hardware. These raster tiles were united via mosaic, cropped to the extent of the Field Office's ownership, and masked to BLM administered surface areas. These data were then aligned with previously generated raster data sets derived from a 10m DEM; when required all re-sampling of these tiles were achieved using cubic spline interpolation.

```{bash NAIP imagery extraction and decoding, eval = F, echo = F}

sudo apt install libtbb-dev libgeos-dev
# install the binary into your home directory 
# http://bin.extensis.com/download/developer/MrSID_DSDK-9.5.1.4427-linux.x86-64.gcc48.tar.gz
# you can test that it now works using an example like:
./mrsiddecode -i infile.sid -o outfile.jpg

# it unfortunately requires that we extract the .sid files from the .zip files!!! 
cd /media/sagesteppe/ExternalHD/NAIP/raw_imagery/

for file in *zip; do

  in_path='/media/sagesteppe/ExternalHD/NAIP/raw_imagery/'
  out_path='/media/sagesteppe/ExternalHD/NAIP/decoded/'
  infilename="$in_path${file%.zip}/${file%.zip}.sid"
  outfilename="$out_path${file%.zip}.tif"
  
  mkdir ${file%.zip}
  unzip $file -d ${file%.zip}
  ~/MrSID_DSDK-9.5.1.4427-linux.x86-64.gcc48/Raster_DSDK/bin/mrsiddecode -i $infilename -o  $outfilename -s 4
  rm -r ${file%.zip} # reduce by  a factor of 4 from 60cm -> 120 -> 240 -> 960 and resample to align with DEM
  
  now=$(date)
  printf "${file%.zip} was processed at: $now\n"
  
done

```

```{r NAIP imagery processing, echo = F, eval = F}

# the first step is to verify that we have all relevant NAIP datasets - i.e. 
# those which intersect the land owernship of the office
UFO_land <- st_read(
  paste0(here(), '/data/processed/UFO_Allotments/', 'UFO_Allotments.shp'),
  quiet = T) %>% 
  st_transform(4269) %>% 
  st_union() %>% 
  st_cast('POLYGON') %>% 
  st_as_sf() %>% 
  st_make_valid()

target_counties <- tigris::counties(state = 'CO') %>% st_make_valid()
target_counties <- target_counties[st_intersection(target_counties, UFO_land),] %>% 
  dplyr::select(COUNTYFP, NAME) %>% 
  st_make_valid()

ggplot(UFO_land) +
  geom_sf( fill = 'black') +
  geom_sf(data = target_counties, fill = NA)

# verify that you have downloaded and processed all relevant county tiles. 
path <- '/media/sagesteppe/ExternalHD/NAIP/decoded'
dl_naip <- list.files(path, pattern = 'tif$')
dl_naip_tiles <- str_extract(dl_naip, '[a-z]{2}[0-9]{3}') %>% 
  str_remove(., '[a-z]{2}') %>% 
  unique()

# Load raster datasets
dl_naip <- file.path(path, dl_naip)
dl_naip_IR <- dl_naip[grep('1-1_hn_s', dl_naip)]
dl_naip_NC <- dl_naip[grep('1-1_hc_s', dl_naip)]

naip_imagery_IR <- lapply(dl_naip_IR, rast)
naip_imagery_NC <- lapply(dl_naip_NC, rast)

target_counties <- target_counties[match(dl_naip_tiles, target_counties$COUNTYFP),]
dl_naip_NC

names(naip_imagery_IR) <- target_counties$NAME
names(naip_imagery_NC) <- target_counties$NAME

# rm(dl_naip, path, dl_naip_IR, dl_naip_NC, target_counties, dl_naip_tiles)

# we need to transform the CRS of several rasters from UTM zone 13 to zone 12

UFO_extent_12 <- vect(st_transform(UFO_land, 26912))
UFO_extent_13 <- vect(st_transform(UFO_land, 26913))

for (i in c(1:2,5:6)){
  naip_imagery_NC[[i]] <- crop(naip_imagery_NC[[i]],  UFO_extent_13, mask = T) # reduce extent of files
}
for (i in c(3,4,7)){
  naip_imagery_NC[[i]] <- crop(naip_imagery_NC[[i]],  UFO_extent_12, mask = T)
}
for (i in c(1,5,2)){
  naip_imagery_NC[[i]] <- project(naip_imagery_NC[[i]],  y = naip_imagery_NC[[4]],
                              method = 'cubicspline', align = T, threads = 20)
}
naip_imagery_NC[[6]] <- project(naip_imagery_NC[[6]],  y = naip_imagery_NC[[5]],
                              method = 'cubicspline', align = T, threads = 20)

naip_imagery_collection_NC <- sprc(naip_imagery_NC) # make a wide raster of all tiles
UFO_NAIP_NC <- mosaic(naip_imagery_collection_NC) # create a single large product of rasters

plot(UFO_NAIP_NC)

path <- '/media/sagesteppe/ExternalHD/NAIP/'
# dir.create(file.path(path, 'processed'))
fname <- file.path(path, 'processed', 'NC_naip.tif')
#tile_borders <- rast(ncols = 2, nrows = 2, crs = crs(UFO_NAIP_NC), 
#                     xmin = xmin(UFO_NAIP_NC), xmax = xmax(UFO_NAIP_NC), 
#                     ymax = ymax(UFO_NAIP_NC), ymin = ymin(UFO_NAIP_NC))
#makeTiles(UFO_NAIP_NC, tile_borders, fname)
writeRaster(UFO_NAIP_NC, fname)

rm(naip_imagery_collection_IR, naip_imagery_collection_NC, naip_imagery_IR, naip_imagery_NC, i)
```


```{r Import processed NAIP imagery and resample to other products, echo = F, eval = F}
path <- '/media/sagesteppe/ExternalHD/NAIP/processed'
files <- list.files(path)

naip_IR <- files[grep('IR_naip.tif', files)]
naip_NC <- files[grep('NC_naip.tif', files)]

naip_IR <- rast(file.path(path, naip_IR))
naip_NC <- rast(file.path(path, naip_NC))

# now we will resample this product so that it aligns with the existing physiographic products we have. 

dem <- rast(file.path( '../data/processed/',
            list.files(file.path('../data/processed'),
            pattern = "dem.*smooth.*tif$")))

naip_IR <- resample(naip_IR, dem, method = 'cubicspline', threads = 20, 
                    filename = file.path(path, 'IR_naip_resamp.tif'))
naip_NC <- resample(naip_NC, dem, method = 'cubicspline', threads = 20, 
                    filename = file.path(path, 'NC_naip_resamp.tif'))
```

```{r settings for texture band creation}
stats <- c("mean", "variance", 'homogeneity', 'contrast', 'dissimilarity')
wind <- c(5, 5)
```


```{r Create Texture Raster band, echo = F, eval = F}

library(factoextra)
library(FactoMineR)
library(glcm)
# https://zia207.github.io/geospatial-r-github.io/texture-analysis.html

# we will perform different runs on the natural color and IR bands to develop the GLCM

path <- '/media/reed/ExternalHD/NAIP/processed'
files <- list.files(path, pattern = 'resamp')

naip_IR_r <- raster::raster(file.path(path, files[grep('IR*', files)]))
naip_NC_r <- raster::raster(file.path(path, files[grep('NC*', files)]))

Sys.time()
glcm.red <- glcm::glcm(naip_IR_r,
                 window = wind, shift = list(c(0,1), c(1,1), c(1,0), c(1,-1)), 
                 statistics = stats, 
                 min_x = 1, max_x = 255, na_opt = 'ignore', na_val = 0)
Sys.time()

Sys.time()
glcm.colour <- glcm::glcm(naip_NC_r,
                 window = wind, shift = list(c(0,1), c(1,1), c(1,0), c(1,-1)), 
                 statistics = stats, 
                 min_x = 1, max_x = 255, na_opt = 'ignore', na_val = 0)
Sys.time()

writeRaster(glcm.colour, file.path(path, 'glcm_red_textures.tif'))
writeRaster(glcm.colour, file.path(path, 'glcm_colour_textures.tif'))

glcm.red <- rast(file.path(path, 'glcm_red_textures.tif'))
glcm.colour <- rast(file.path(path, 'glcm_colour_textures.tif'))

rm(naip_IR_r, naip_NC_r)

## we determine which bands contain the most variation using a PCA
all_textures <- c(glcm.red, glcm.colour)
all_textures <- scale(all_textures, center = T) # scale the data before the function
all_textures[is.na(all_textures)] <- 0 # define zero for all missing values

Sys.time()
texture_values <- values(spatSample(all_textures, # this can take up to an hour or so
                                    ((dim(all_textures)[1] * dim(all_textures)[2]) * 0.01), 
                        as.raster=TRUE))
Sys.time()
rf_veg_pca <- prcomp(texture_values)

saveRDS(rf_veg_pca, "../results/stats/veg_pca.rds")
rf_veg_pca <- readRDS("../results/stats/veg_pca.rds")
texture_PC <- predict(all_textures, rf_veg_pca)

fviz_pca_var(rf_veg_pca,
             col.var = "contrib", # Color by contributions to the PC
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE     # Avoid text overlapping
)

summary(rf_veg_pca)
rf_veg_pca[["rotation"]]

# now select and write out bands with considerable influence to variation
texture_PrincComponents <- subset(texture_PrincComponents, c(1:2))
names(texture_PrincComponents) <- paste0('principal_Component', 
                                         rep(1:dim(texture_PrincComponents)[3]))

plot(texture_PrincComponents)
texture_PrincComponents <- mask(texture_PrincComponents, glcm.red)
plot(texture_PrincComponents)

writeRaster(texture_PrincComponents, file.path(path, 'Textures_pca.tif'), overwrite = T)

rm(texture_PrincComponents, all_textures, glcm.red, glcm.colour, texture_values, rf_veg_pca, texture_PC, files, sr)
```

A Gray Level Co-occurrence Matrix (GLCM) was created using the 'glcm' package to create a texture raster layer to aid in classification. Texture bands are, among other properties, capable of indicating the amounts of heterogeneity of habitat types across the landscape. Texture layers were produced using both NAIP natural color and infrared imagery. Texture statistics: `r toString(paste0(stats))`, with windows of `r toString(wind[1])` in both direction, shifts in all directions (**Queen's case**), and the default value of 32 grey levels. NAIP data were processed to create an NDVI band. NDVI is well suited for identifying sparsely vegetated areas, it may be useful in distinguishing salt desert from all other strata, and help in distinguishing between MMS and PJ. 

```{r create NDVI band, echo = F, eval = F}
# (NIR - Red) / (NIR + Red)

naip_NC <- rast(naip_NC_r)
naip_IR <- rast(naip_IR_r)
rm(naip_IR_r, naip_NC_r)

naip_ndvi <- (naip_IR[[1]] - naip_NC[[1]]) / (naip_IR[[1]] + naip_NC[[1]])
plot(naip_ndvi) # see the green up at the boundaries with forest service.

writeRaster(naip_ndvi, file.path(path, 'NDVI.tif'), overwrite = T)
```

```{r Export Points for Manual Classification in Google Earth, echo = F, eval = F}

rndm_VegPts <- st_read(
  file.path(here(), '/data/processed/UFO_Allotments/', 'UFO_Allotments.shp'),
  quiet = T) %>%
  st_union() %>%
  vect()

rndm_VegPts <- rndm_VegPts
  spatSample(size = 150, method="random") %>%
  st_as_sf() %>%
  mutate(ID = 1:n()) %>%
  select(ID) %>%
  st_transform(4326) %>%
  as('Spatial')

rndm_VegPts2 <- rndm_VegPts %>%
  spatSample(size = 250, method="random") %>%
  st_as_sf() %>%
  mutate(ID = 1:n()) %>%
  select(ID) %>%
  st_transform(4326) %>%
  as('Spatial')
 
maptools::kmlPoints(rndm_VegPts, kmlfile = '../data/raw/UFO_Random_Veg_pts.kml',
          name = rndm_VegPts[['ID']], kmlname = 'Random_Veg_pts')
maptools::kmlPoints(rndm_VegPts2, kmlfile = '../data/raw/UFO_Random_Veg_pts2.kml',
          name = rndm_VegPts2[['ID']], kmlname = 'Random_Veg_pts2')

# we will also write a CSV for noting the results quickly.
rndm_VegPts <- rndm_VegPts %>%
  st_as_sf() %>%
  mutate('VegClass' = "",
    'Longitude' = st_coordinates(.)[,1],
    'Latitude' = st_coordinates(.)[,2]) %>%
  st_drop_geometry()
write.csv(rndm_VegPts, file = '../data/raw/UFO_Random_Veg_pts.csv' , row.names = F)
rndm_VegPts2 <- rndm_VegPts2 %>%
  st_as_sf() %>%
  mutate('VegClass' = "",
    'Longitude' = st_coordinates(.)[,1],
    'Latitude' = st_coordinates(.)[,2]) %>%
  st_drop_geometry()
write.csv(rndm_VegPts2, file = '../data/raw/UFO_Random_Veg_pts2.csv' , row.names = F)

rglr_VegPts <- rndm_VegPts %>%
  spatSample(size = 150, method="regular") %>%
  st_as_sf() %>%
  mutate(ID = 1:n()) %>%
  select(ID) %>%
  st_transform(4326) %>%
  as('Spatial')
 
maptools::kmlPoints(rglr_VegPts, kmlfile = '../data/raw/UFO_Regular_Veg_pts.kml',
          name = rglr_VegPts[['ID']], kmlname = 'Regular_Veg_pts')

# get some more. 
rglr_VegPts <- rndm_VegPts %>%
  spatSample(size = 750, method="regular") %>%
  st_as_sf() %>%
  mutate(ID = 1:n()) %>%
  select(ID) %>%
  st_transform(4326) %>%
  as('Spatial')

maptools::kmlPoints(rglr_VegPts, kmlfile = '../data/raw/UFO_Regular_Veg_pts2.kml',
          name = rglr_VegPts[['ID']], kmlname = 'Regular_Veg_pts2')

# we will also write a CSV for noting the results quickly.
rglr_VegPts <- rglr_VegPts %>%
  st_as_sf() %>%
  mutate('VegClass' = "",
    'Longitude' = st_coordinates(.)[,1],
    'Latitude' = st_coordinates(.)[,2]) %>%
  st_drop_geometry()
write.csv(rglr_VegPts, file = '../data/raw/UFO_Regular_Veg_pts2.csv' , row.names = F)


# we will also write out the 2022 plots to KML for manual classification. 
aim2022 <- st_read(file.path(here(), '/data/raw/AIM_Points_2022/', 'AIM_Points_2022.shp'),
        quiet = T) %>% 
  mutate(ID = 1:n()) %>%
  select(ID) %>%
  st_transform(4326) %>%
  as('Spatial')

maptools::kmlPoints(aim2022, kmlfile = '../data/raw/UFO_2022_AIM.kml',
          name = aim2022[['ID']], kmlname = 'UFO_2022_AIM')
aim2022 <- aim2022 %>%
  st_as_sf() %>%
  mutate('VegClass' = "",
    'Longitude' = st_coordinates(.)[,1],
    'Latitude' = st_coordinates(.)[,2]) %>%
  st_drop_geometry()
write.csv(aim2022, file = '../data/raw/UFO_2022_AIM.csv' , row.names = F)

rm(rndm_VegPts, rndm_VegPts2, aim2022)
```


```{r Read in classified points from GE and AIM, echo = F, warning = F, message = F}
random <- file.path('../data/processed/',
  list.files('../data/processed/',  pattern = '*Random*'))
reg <- file.path('../data/processed/',
  list.files('../data/processed/',  pattern = '*Regular*'))

twenty22 <- read.csv('../data/processed/UFO_2022_AIM_CLASSIFIED.csv')
historicVeg <- read.csv('../data/processed/UFO_Veg_monitoring_CLASSIFIED.csv') %>% 
  na_if("")
plot_drawn <- (nrow(twenty22) + nrow(historicVeg))
plot_class <- bind_rows(twenty22, historicVeg) %>% drop_na()

reg_drawn <- do.call(rbind, lapply(reg, function(x) 
  read.csv(x, stringsAsFactors = FALSE)))
reg_pts <- reg_drawn %>% 
  drop_na() %>% 
  filter(VegClass %in% c('AS', 'MC', 'PJ', 'SD', 'SS', 'MMS'))

random_drawn <- do.call(rbind, lapply(random, function(x) 
  read.csv(x, stringsAsFactors = FALSE))) %>% 
  na_if("") 
random_pts <- random_drawn %>% drop_na() 

rm(random, twenty22, historicVeg)
```

To create data set for training a random forest model, all `r toString(plot_drawn)` sampled AIM and LMF points LMF points, from 2018-2022, as well as all drawn 2022 AIM points, were exported to Google Earth and `r toString(nrow(plot_class))` were classified. `r toString(nrow(random_drawn))` random points were generated across the field office and `r toString(nrow(random_pts))` classified in Google Earth via the vegetation ecologist which lead the AIM sampling in 2022. An additional `r toString(nrow(reg_drawn))` regularly placed plots were drawn across the extent of the field office and `r toString(nrow(reg_pts))` were classified. Unclassified computer generated points were generally those that fell upon a wide road, or were outside BLM Ownership. Unclassified AIM/LMF points were LMF points which must have represented the re-visitation of a single plot, under distinct record elements in the TerraDat database. In all instances points were buffered by a 30m radius, to create the dimensions of an AIM plot, and the single most influential vegetation type was recorded.

```{r buffer points from GE and AIM , echo = F}

p <- file.path(here::here(), 'data/processed')

reg_pts <-  reg_pts %>% 
  st_as_sf(coords = c("Longitude", "Latitude"), crs = 4326) %>% 
  mutate(Type = 'Regular', .after = 'ID') %>% 
  mutate(ID = as.character(ID)) %>% 
  st_transform(26912) %>% 
  st_buffer(30) 

random_pts <- random_pts %>% 
  st_as_sf(coords = c("Longitude", "Latitude"), crs = 4326) %>% 
  mutate(Type = 'Random2', .after = 'ID') %>% 
  st_transform(26912) %>% 
  st_buffer(30) %>% 
  mutate(ID = as.character(ID)) %>% 
  mutate(across(where(is.character), ~na_if(., ""))) %>%
  filter(VegClass %in% c('PJ', 'SD', 'SS', 'MMS'))

veg_pts <- plot_class %>% 
  st_as_sf(coords = c("Longitude", "Latitude"), crs = 4326) %>% 
  mutate(Type = 'Stratified', .after = 'ID') %>% 
  st_transform(26912) %>% 
  st_buffer(30) %>% 
  mutate(ID = as.character(ID))

# AIM DATA post K-Means is read in here
#veg_pts <- st_read(file.path(p, '/reclassified_AIM/reclassified_AIM.shp'), quiet = T) %>% 
#  st_transform(26912) %>%  # these alreday buffered by type. 
#  rename(ID = PlotKey, Type = Plot, VegClass = Veg_type) %>% 
#  bind_rows(., computer_pts) %>% 
#  drop_na() %>% 
#  vect()

# alt route use the manually classified
veg_pts <- bind_rows(veg_pts, random_pts, reg_pts) %>% 
  as(., "Spatial") %>% 
  vect()

rm(reg_pts, random_pts, plot_drawn, random_drawn, reg_drawn)
```

```{r Import all Geographic Data and extract occurrences to points, eval = F}

UFO_land <- st_read(
  paste0(here(), '/data/processed/UFO_Allotments/', 'UFO_Allotments.shp'),
  quiet = T) %>% 
  st_transform(4269) %>% 
  st_union() %>% 
  st_cast('POLYGON') %>% 
  st_as_sf() %>% 
  st_make_valid() %>% 
  st_transform(26912) %>% 
  vect()

path <- '/media/sagesteppe/ExternalHD/NAIP/processed'
files <- list.files(path)
files
naip_NC <- rast(file.path(
  path, files[grep('NC_naip_resamp.tif', files)]))
naip_IR <- rast(file.path(
  path, files[grep('IR_naip_resamp.tif', files)]))[[1]]
NDVI <- rast(file.path(
  path, files[grep('NDVI.tif', files)]))

texture <- rast(file.path(
  path, files[grep('Textures_pca.tif', files)]))
texture <- resample(texture, naip_NC, method = 'cubicspline')

PhysioPath <- '/media/sagesteppe/ExternalHD/AIM_Field_rasters'

DEM <- rast(file.path(PhysioPath,
            list.files(PhysioPath,
            pattern = "dem.*smooth.*tif$")))
DEM <- crop(DEM,  UFO_land, mask = T)
DEM <- resample(DEM, naip_NC, method = 'cubicspline')

slope <- rast(file.path(PhysioPath,
            list.files(PhysioPath,
            pattern = "slope*")))
slope <- terra::project(slope,  y = DEM, method = 'cubicspline', align = T)
slope <- crop(slope,  UFO_land, mask = T)
slope <- resample(slope, naip_NC, method = 'cubicspline')

predictors <- c(naip_NC, naip_IR, NDVI, texture, DEM, slope)
names(predictors) <- c('NAIP_red', 'NAIP_green', 'NAIP_blue', 'NAIP_IR', 'NDVI', 
                       'GLCM_PC1', 'GLCM_PC2', 'DEM', 'Slope')

rm(naip_NC, texture, DEM, slope, PhysioPath, UFO_land, files, naip_IR, NDVI, path)
```

```{r set random forest model parameters proportion, echo  = F}
train_prop <- 0.7
mTry <- 4
nTT <- 1000
sF <- 1.5
I <- 0.01
```

```{r Extract Predictor Variables to Points and create partitions, message = F, warning = 'hide', eval = F}
library(caret)
library(parallel)
library(doParallel)
library(randomForest)

veg_pts <- project(veg_pts, crs(predictors))
VegClass <- extract(predictors, veg_pts, method = 'simple', touches = F, fun = mean )#,
                  #  weights = T) # note weights work on Lightscape, but not parkland. 
VegClass <- cbind(as.data.frame(veg_pts), VegClass[,2:ncol(VegClass)])
VegClass <- VegClass[complete.cases(VegClass),]
VegClass <- cbind(VegClass[,4:ncol(VegClass)], 'class' = VegClass[,3])
VegClass$class <- as.factor(VegClass$class)

split_obs <- createDataPartition(VegClass$class,
                                 p = train_prop, # percentage of data as training
                                 list = FALSE)
train <- VegClass[split_obs,]
test <- VegClass[-split_obs,]

# here we gather a similar number of records to test the original stratification
# note we subset out the data which were drawn from the GAP data set. 


test <- read.csv(file.path('../data/processed/', 'rf_testing_data.csv'))


vp <- st_as_sf(veg_pts) %>%
  filter(Type != 'Stratified',
         VegClass %in% c('AS', 'MC', 'PJ', 'MMS', 'SD', 'SS')) %>% # only test on same vegclasses!!! 
  mutate(VegClass = as_factor(VegClass))
second_test <- ( 1 - (nrow(test) / nrow(vp) )) * 0.9 # alot of the values in original will NaN buffet it a bit
split_obs_strat <- createDataPartition(vp$VegClass,
                                 p = second_test, # percentage of data as training
                                 list = FALSE)
testOriginal <- vp[-split_obs_strat,]

mainDir <- '../data/processed/'
subDir <- 'StratTest'

# here we create the 
ifelse(!dir.exists(file.path(mainDir, subDir)), dir.create(file.path(mainDir, subDir)), FALSE)
st_write(testOriginal, file.path(mainDir, subDir, 'TestSetStratification.shp'), quiet = T)
# write.csv(test, file.path(mainDir, 'rf_testing_data.csv'), row.names  = F)

rm(VegClass, split_obs, testOriginal, vp, mainDir, subDir, testOriginal, split_obs_strat)
```

To develop a random forest model, the dataset of `r toString(nrow(veg_pts))` classified points were partitioned into a `r toString(1-train_prop)` test and training set `r toString(train_prop)` using 'caret', the data set was not balanced, see table XX for sample sizes.  

```{r Fit Random Forest Model, warning = F, message = F, eval = F}

opt_mtry <- tuneRF(train, train$class, ntreeTry = nTT,
               stepFactor = sF, improve = I, trace = TRUE, plot = TRUE)

cl <- makeCluster(detectCores()-2)
registerDoParallel(cl)
veg_rf_model <- randomForest(class~., data=train, proximity=TRUE, 
                             ntree = nTT, mtry = 9)
stopCluster(cl); remove(cl)

saveRDS(veg_rf_model, file = paste0('../results/stats/RandomForest', Sys.Date(), '.rds'))

rm(cl, train, opt_mtry)
```

```{r Random Forest Results, echo = F, warning = F, message = F}

prds <- '/media/sagesteppe/ExternalHD/plot_post_stratification/results/stats'
veg_rf_model <- readRDS(file = file.path(prds, 'RandomForest2022-10-31.rds'))
test <- read.csv(file.path('../data/processed/', 'rf_testing_data.csv'))
test$class <- as.factor(test$class)

data.frame(randomForest::importance(veg_rf_model, type = 2)) %>% 
  rownames_to_column('Variable') %>% 
  arrange(-MeanDecreaseGini) %>% 
  knitr::kable( col.names = c('Variable', 'Importance'),  align = "l", digits = 3,
                caption = "Variable Importance in Random Forest Model")

# plot(veg_rf_model) # beyond the scope of the write-up
# generate a confusion matrix to determine accuracy on real data

test_prediction <- predict(veg_rf_model, test)
cm1 <- caret::confusionMatrix(test_prediction, test$class)

knitr::kable(cm1$table, caption = 'Confusion matrix for RF model')
#knitr::kable()

rm(test_prediction, train_prop, test, prds)
```

```{r original GAP evaluation, echo = F, warning = F}

p <- '/media/sagesteppe/ExternalHD/UFO_AIM_Design_Stratification'
pts2test <- st_read('../data/processed/StratTest/TestSetStratification.shp', quiet = T) %>% vect()
gap <- rast('/media/sagesteppe/ExternalHD/UFO_AIM_Design_Stratification/processed/UFO_Strata.tif')
pts2test <- project(pts2test, crs(gap))
reprocessedGAP <- read.csv(file.path(p, 'processed', 'UFO_strata_areas.csv')) %>% 
  select(RasterValue, Code)
factor_lvls <- c("AS", "MC", "MMS", "PJ", "SD", "SS", "RI", "OT", "GR", "PP" )

a <- extract(gap, pts2test, method = 'simple', touches = F)
a <- a[complete.cases(a),]

pts2test <- st_as_sf(pts2test) %>% 
  st_drop_geometry() %>% 
  select(VegClass) %>% 
  rowid_to_column('ID') 

mdsOrig <- a %>% 
  group_by(ID) %>% # these are the original values. 
  summarise(OriginalCover = Mode(BPS_CODE)) %>% 
  left_join(., pts2test, by = 'ID') %>% 
  left_join(., reprocessedGAP, by = c('OriginalCover' = 'RasterValue')) %>% 
  select(True = VegClass, Original = Code) %>% 
  mutate(across(.cols = everything(), ~ factor(.x, levels = factor_lvls)))

caret::confusionMatrix(mdsOrig$True, mdsOrig$Original)

rm(pts2test, factor_lvls, a, mdsOrig)
```

The number of mtry in the random forest model were tuned using the function 'tuneRF' with the number of try's set to `r toString(nTT)`, a step factor of `r toString(sF)` and a relative minimum improvement in Out of Bag (OOB) error rate set at `r toString(I)`. The random forest model was then trained using `r toString(mTry)` mtry and `r toString(nTT)` trees, all using the RandomForest package. 

While the accuracy for the model was `r toString(round(cm1[["overall"]][["Accuracy"]],3))` (range `r toString(round(cm1[["overall"]][["AccuracyLower"]],2))` - `r toString(round(cm1[["overall"]][["AccuracyUpper"]], 2))` 95 % confidence interval), due to an imbalance in the number of observations per group a more appropriate for evaluating the overall performance of the model, is the Kappa metric, `r toString(round(cm1[["overall"]][["Kappa"]], 3))`.

Notably, the model has high rates of Specificity (median = `r toString(round(median(cm1[[4]][, grep('Spec', colnames(cm1[[4]]))]), 2))`), showing that when it predicts a vegetation type onto a pixel cell, the prediction is usually correct; less so for prediction of Pinon-Juniper (`r toString(round(cm1[[4]][grep('PJ', rownames(cm1[['byClass']]) ,'MMS') , grep('Spec', colnames(cm1[[4]])) ], 3))`). However, the model suffers from low Sensitivity, indicating that it is unable to detect all occurrences of a vegetation type. For example, the model is only able to appropriately classify half of the occurrences of Sage Steppe (`r toString(round(cm1[[4]][grep('SS', rownames(cm1[['byClass']]) ,'MMS') , grep('Sens', colnames(cm1[[4]])) ], 3))`
) and Mixed Mountain Shrub (`r toString(round(cm1[[4]][grep('MMS', rownames(cm1[['byClass']]) ,'MMS') , grep('Sens', colnames(cm1[[4]])) ], 3))`). Accordingly this model is susceptible to over-predicting the occurrence of Pinyon-Juniper, at the expense of Mixed Mountain Shrub and Sagesteppe. This is to be expected given the sample imbalance, which contained many more plots PJ than other types. However numerous trials of reducing the number of Pinyon-Juniper plots did not significantly increase the quality of predictions. Further indicating, that the features used are not adequate for distinguishing between the transitional points enough Pinons and Junipers are present where Sagesteppe phases into Pinyon-Juniper, and where shrubs increase in Pinyon-Juniper and it phases into Mixed-Mountain Shrub. 

Compared to the original model.... *remember evaluation of the original model is same Sample size as evaluation of post-strat HOWEVER it is drawn only from the random and regular points to be independent of the AIM points drawn from it*

```{r remove tree parameters, echo = F, warning = F}
rm(mTry, nTT, I, sF)

```

```{r Predict random forest onto raster and smooth it, eval = F}

# predict model onto raster
predict_rf <- terra::predict(object = predictors, model = veg_rf_model, cpkgs = 'randomForest',
                     filename = file.path(p, '/PredictedVegClass.tif'),
                     overwrite = T)

# smooth the raster using focal statistics, we will find the mode in a rolling 
# window and re-assign values based upon that. 
predict_rf_smooth <- focal(predict_rf, w = 5, fun = modal, na.policy= 'omit')
plot(predict_rf_smooth, col = c('#e41a1c', '#377eb8', '#4daf4a', '#984ea3', '#ff7f00','#ffff33'))

predict_rf <- writeRaster(predict_rf_smooth, file.path(here(), '/data/processed/PredictedVegClass-sm.tif'), overwrite = T)
```

The Random Forest classification model was predicted onto a raster surface using the package 'Terra.' This raster was then smooth using focal statistics, with a window of 5 cells, using the mode as the value to return. 

```{r Compare to original stratification}
testOriginal <- st_read('../data/processed/StratTest/TestSetStratification.shp', quiet = T) %>%
  vect()

pstrat <- '/media/sagesteppe/ExternalHD/UFO_AIM_Design_Stratification/processed/'
original_strat <- rast(file.path(pstrat, "UFO_Strata.tif"))

testOriginal <- project(testOriginal, crs(original_strat))
outOrig <- extract(original_strat, testOriginal, method = 'simple')
outOrig <- outOrig[complete.cases(outOrig),]

post_strat <- rast(file.path(here(), '/data/processed/PredictedVegClass-sm.tif'))
testOriginal <- project(testOriginal, crs(post_strat))
outPost <- extract(post_strat, testOriginal, method = 'simple')
outPost <- outPost[complete.cases(outPost),]

mdsOrig <- outOrig %>%
  group_by(ID) %>% # these are the original values. 
  summarise(OriginalCover = Mode(BPS_CODE))

mdsPost <- outPost %>% 
  group_by(ID) %>% 
  summarise(RestratifiedCover = Mode(lyr1))

change <- inner_join(mdsOrig, mdsPost, by = 'ID')

rm(testOriginal, mdsOrig, mdsPost, Mode, post_strat, outPost, outOrig, original_strat)
```

# Comparison of New and Old vegetation classification models. 

```{r make waffle charts of changes in vegetation, echo = F,  fig.height = 8, fig.width = 3, fig.cap = "Changes in Predicted Land Cover", out.width= "50%", out.extra='style="float:left; padding:10px"'}

library(waffle)
library(tidyverse)
library(cowplot)

strata_pal <- setNames(
  c('#4A5A28', '#ADB1B9', '#CEB88E', '#574039', '#B64841',
    '#1357a6', '#1B1212', '#F9E076', '#39993A', '#00688B'),
  c('PJ', 'SS', 'SD', 'MMS', 'AS', 'RI', 'OT', 'GR', 'PP', 'MC')
)

# original land cover of sample design

p <- '/media/sagesteppe/ExternalHD/UFO_AIM_Design_Stratification'
initialGAP <- read.csv(file.path(p, 'raw', 'lookupTable.txt'))

reprocessedGAP <- read.csv(file.path(p, 'processed', 'UFO_strata_areas.csv')) %>% 
  mutate(Percent = round((Cells/sum(Cells) ) *100)) %>% 
  arrange(-Percent)

strata_pal <- strata_pal[order(match(names(strata_pal),reprocessedGAP$Code))]

strata_waffle <- ggplot(reprocessedGAP, aes(fill = Code, values = Percent)) + 
  geom_waffle(color = 'white') + 
  scale_fill_manual(name = 'Statum',
                    values = strata_pal, 
                    labels = names(strata_pal)) + 
  coord_equal() + 
  theme_void() + 
  labs(title = 'initial stratification')  +
  guides(fill=guide_legend(ncol=2)) +
  theme(plot.title = element_text(hjust = 0.5), 
        legend.title.align = 0.5,
        plot.margin = unit(c(0.25,0.25,0.25,0.25), "cm"))

legend <- get_legend(strata_waffle)
strata_waffle <- strata_waffle + theme(legend.position='none')

# now a waffle of what percent habitat plots were located actually IN ??

veg_pts <- veg_pts %>% 
  st_as_sf() %>% 
  st_drop_geometry() %>% 
  filter(Type != 'Stratified') %>% 
  group_by(VegClass) %>% 
  count() %>% 
  ungroup() %>% 
  mutate(Percent = round((n/sum(n))*100 ))  %>% 
  arrange(-Percent)

strata_pal <- strata_pal[order(match(names(strata_pal),veg_pts$VegClass))]
strata_pal3 <- strata_pal[1:nrow(veg_pts)]

random_waffle <- ggplot(veg_pts, aes(fill = VegClass, values = Percent)) + 
  geom_waffle(color = 'white') + 
  scale_fill_manual(name = 'Statum',
                    values = strata_pal3, 
                    labels = names(strata_pal3)) + 
  coord_equal() + 
  theme_void() + 
  theme(legend.position="none") +
  labs(title = 'human classification')  +
  theme(plot.title = element_text(hjust = 0.5),
        plot.margin = unit(c(0.25,0.25,0.25,0.25), "cm"))

#  a waffle of what percent habitats exist in UFO based on reclassification

reclassified <- rast(file.path(here(), 'data/processed/PredictedVegClass.tif'))

#plot(reclassified, col = c('#e41a1c', '#377eb8', '#4daf4a', '#984ea3', '#ff7f00','#ffff33'))
area <- values(reclassified)
area <- area[!is.na(area)] # 4 SS, # 3 SD, 2 PJ, 1 MMS
area <- aggregate(area, list(num=area), length)

ltable <- data.frame(
  num = c(1, 2, 3, 4, 5, 6), 
  Stratum = c('AS', 'MC', 'MMS', 'PJ', 'SD', 'SS')
) 

vegclass <- area %>% 
  inner_join(., ltable, 
            by = 'num') %>% 
  select(Cells = x, RasterValue = num, Stratum) %>% 
  mutate(Percent = round((Cells/sum(Cells) ) *100)) %>% 
  arrange(-Percent)

strata_pal <- strata_pal[order(match(names(strata_pal),vegclass$Code))]
strata_pal2 <- strata_pal[1:nrow(vegclass)]

reclass_waffle <- ggplot(vegclass, aes(fill = Stratum, values = Percent)) + 
  geom_waffle(color = 'white') + 
  scale_fill_manual(name = 'Statum',
                    values = strata_pal2, 
                    labels = names(strata_pal2)) + 
  coord_equal() + 
  theme_void() + 
  theme(legend.position="none") + 
  labs(title = 're-modelled classification')  +
  theme(plot.title = element_text(hjust = 0.5),
        plot.margin = unit(c(0.25,0.25,0.25,0.25), "cm"))

plot_col <- plot_grid(strata_waffle, random_waffle,
                      reclass_waffle, legend, ncol = 1, rel_widths = c(1,1,1,0.75),
                      rel_heights = c(1,1,1,0.75))

title <- ggdraw() + 
  draw_label(
    "Percent Land Cover",
    fontface = 'bold',
    x = 0,
    hjust = 0
  ) + theme(plot.margin = ggplot2::margin(0, 0, 0, 1.5,  "cm"))

plot_grid(
  title, plot_col,
  ncol = 1,
  # rel_heights values control vertical title margins
  rel_heights = c(0.1, 1) 
)

rm(strata_pal2, strata_pal3, random_waffle, reclass_waffle, legend, plot_col)
```

a ton of test words that should wrap right.... seem like needs more work 
 
this town 
is coming
 
like a ghost
 
town 
 
bands wont
play no more
too much fighting
on the dance floor


```{r compare values between rasters to create flow chart, eval = F}
# first match the resolutions of these products, we will resample the coarser original
# to the finer remapped classification. 
original_strat <- rast(file.path(p, 'processed', 'UFO_Strata.tif'))
rm(original_strat)

area <- values(orig_strat_resamp)
area <- area[!is.na(area)] 
area <- aggregate(area, list(num=area), length)
area <- area %>% 
  inner_join(., reprocessedGAP %>% select(RasterValue, Code), 
            by = c('num' = 'RasterValue')) %>% 
  rename(Cells = x)

# probably dont try the following on gov't computer, reach out to reed (sagesteppe) and he can run it
r <- rast(list(orig_strat_resamp, reclassified))
rvals <- as.matrix(r, na.rm = T)
rvals <- rvals[complete.cases(rvals),]
rvals <- data.frame(rvals) %>% 
  group_by(lyr1) %>% 
  count(BPS_CODE) %>% 
  rename(Reclassified = lyr1,
        Original= BPS_CODE)

p1 <- '/media/sagesteppe/ExternalHD/plot_post_stratification/data/processed'
write.csv(rvals, file.path(p1, 'Extracted_raster_values.csv'), row.names = F)
write.csv(area, file.path(p1, 'Count_OriginalStrat_raster_values.csv'), row.names = F)
rm(d, original_strat, reclassified)
```

```{r reimport data for showing flow from veg classes, echo = F, fig.cap= "Depiction of how raster cells in the UFO are redistributed from the original sample design (lower half), to the the reclassified spatial product for the sample design (upper half)", fig.height = 6, fig.width = 6}

shhh(library(circlize))
p1 <- '/media/sagesteppe/ExternalHD/plot_post_stratification/data/processed'
rvals <- read.csv(file.path(p1, 'Extracted_raster_values.csv'))
area <- read.csv(file.path(p1, 'Count_OriginalStrat_raster_values.csv'))

rvals <- rvals %>% 
  mutate(n = (n/sum(n))*100) %>% 
  pivot_wider(names_from = 'Reclassified', values_from = 'n') %>% 
  column_to_rownames('Original') %>% # for circle chart. 
  as.matrix()

colnames(rvals) <- paste0('to', ltable$Stratum)
rownames(rvals) <- reprocessedGAP %>% 
  arrange(RasterValue) %>% 
  pull(Code)
sp2 <- strata_pal # create a palette to mark the colors in both ends
names(sp2) <- paste0('to', names(strata_pal))
all_pals<- c(strata_pal, sp2)

#circos.par(gap.after = c("AS" = 5, "GR" = 5, "MC" = 5, "MMS" = 5, "OT" = 5, 
#                          "PJ" = 1, "PP" = 5,  "RI" = 5,  "SS" = 0,  "SD" = 0, 
#                         "toAS" = 5, "toMC" = 5, "toMMS" = 0, "toPJ" = 0, "toSD" = 0, "toSS" = 5))
par(mar = c(1.5, 1.5, 4.1, 1.5))
circos.par(start.degree = 0)
chordDiagram(rvals, transparency = 0.5, directional = 1, 
             grid.col = all_pals, diffHeight  = -0.04, big.gap = 10)
abline(h = 0, lty = 2, col = "#00000080")
title("Movement of Pixels from stratification\n(bottom) to post stratification (top)")
circos.clear()
```

The initial AIM sample design was based upon a stratification which included `r` communities. This design was based on a manual reclassification of the GAP/LANDFIRE National Terrestrial Ecosystems 2011 data set. 

# Citations

```{r Citations, echo = F, comment = ""}
c("terra", "glcm", "RStoolbox", "randomForest", "caret", "parallel", "doParallel") %>%
  map(citation) %>%
  print(style = "text")

```

