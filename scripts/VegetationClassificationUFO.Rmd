---
title: "Vegetation_Classification"
author: "steppe"
date: "2022-10-03"
output:
  word_document: default
  html_document: default
---

The initial AIM sample design for each office was based upon small stratified areas - (Primary Sampling Units) PSU's which up to 3 plots per each of are to make inference of. The primary sampling units were based on older vegetation classification projects which do not perform as high as other mechanisms. 

We have used the in field AIM data to reclassify a number of plots in unusual strata such as: 'Other', 'Mixed Conifer', and 'Riparian'. We will use all of this reclassified AIM data to determine whether the PSU on the whole is classified as the same vegetation type as the points which were sampled within it. 

To do this a very simple vegetation classification will be performed using a handful of spatial products. The central product will be the National Aerial Imagery Programs flight data. Supplemental data includes a 10m DEM which was previously re-processed using WhiteBoxTools, a 10m resolution slope dataset, and a 10m landform classification dataset. 
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F)
knitr::opts_chunk$set(message = "hide")
knitr::opts_chunk$set(warning = "hide")
```

```{r Load Libraries}
library(tidyverse)
library(terra)
library(sf)
library(here)
set.seed(72)
```

# Methods 

```{r Import and Subset AIM, echo = F, eval = F}

UFO_buffered <- st_read(
  paste0(here(), '/data/raw/BLM_CO_Administrative_Units/', 'admu_ofc_poly.shp'),
  quiet = T) %>% 
  filter(ADMU_NAME == 'UNCOMPAHGRE FIELD OFFICE') %>% 
 # st_buffer(32186) %>%  # buffer the FO by 20 miles
  st_transform(4269) %>% 
  dplyr::select(ADMU_NAME)

AIM_plots <- st_read('/media/sagesteppe/ExternalHD/aimDB/summaries/TerrADat.shp', quiet = T) %>% 
  dplyr::select(PrimaryKey:PlotID)
AIM_plots <- st_intersection(UFO_buffered,  AIM_plots) %>% 
  select(-ADMU_NAME)
PIntercept <- read.csv('/media/sagesteppe/ExternalHD/aimDB/PIntercept.txt')

plots <- left_join(AIM_plots, PIntercept, by = c('PrimaryKey' = 'PrimaryKey'))

rm(UFO_buffered)
```

NAIP Imagery for Colorado 2019 was downloaded from the official repository at Box in Fall 2022. While decoding from MrSID to tif file formats, their resolution was reduced by a factor of two using the 'mrsiddecode' program (Vers. 9.5.1.4427) from LizardTech. These raster tiles were united via mosaic, cropped to the extent of the Field Office Buffer, and masked to BLM administered surface areas. and they were aligned with previously generated raster datasets derived from a 10m DEM. 

```{bash NAIP imagery extraction and decoding, eval = F, echo = F}

sudo apt install libtbb-dev libgeos-dev
# install the binary into your home directory 
# http://bin.extensis.com/download/developer/MrSID_DSDK-9.5.1.4427-linux.x86-64.gcc48.tar.gz
# you can test that it now works using an example like:
./mrsiddecode -i infile.sid -o outfile.jpg

# it unfortunately requires that we extract the .sid files from the .zip files!!! 
cd /media/sagesteppe/ExternalHD/NAIP/raw_imagery/

for file in *zip; do

  in_path='/media/sagesteppe/ExternalHD/NAIP/raw_imagery/'
  out_path='/media/sagesteppe/ExternalHD/NAIP/decoded/'
  infilename="$in_path${file%.zip}/${file%.zip}.sid"
  outfilename="$out_path${file%.zip}.tif"
  
  mkdir ${file%.zip}
  unzip $file -d ${file%.zip}
  ~/MrSID_DSDK-9.5.1.4427-linux.x86-64.gcc48/Raster_DSDK/bin/mrsiddecode -i $infilename -o  $outfilename -s 4
  rm -r ${file%.zip} # reduce by  a factor of 4 from 60cm -> 120 -> 240 -> 960 and resample to align with DEM
  
  now=$(date)
  printf "${file%.zip} was processed at: $now\n"
  
done

```

```{r NAIP imagery processing, echo = F, eval = F}

# the first step is to verify that we have all relevant NAIP datasets - i.e. 
# those which intersect the land owernship of the office
UFO_land <- st_read(
  paste0(here(), '/data/processed/UFO_Allotments/', 'UFO_Allotments.shp'),
  quiet = T) %>% 
  st_transform(4269) %>% 
  st_union() %>% 
  st_cast('POLYGON') %>% 
  st_as_sf() %>% 
  st_make_valid()

target_counties <- tigris::counties(state = 'CO') %>% st_make_valid()
target_counties <- target_counties[st_intersection(target_counties, UFO_land),] %>% 
  dplyr::select(COUNTYFP, NAME) %>% 
  st_make_valid()

ggplot(UFO_land) +
  geom_sf( fill = 'black') +
  geom_sf(data = target_counties, fill = NA)

# verify that you have downloaded and processed all relevant county tiles. 
path <- '/media/sagesteppe/ExternalHD/NAIP/decoded'
dl_naip <- list.files(path, pattern = 'tif$')
dl_naip_tiles <- str_extract(dl_naip, '[a-z]{2}[0-9]{3}') %>% 
  str_remove(., '[a-z]{2}') %>% 
  unique()

# Load raster datasets
dl_naip <- file.path(path, dl_naip)
dl_naip_IR <- dl_naip[grep('1-1_hn_s', dl_naip)]
dl_naip_NC <- dl_naip[grep('1-1_hc_s', dl_naip)]

naip_imagery_IR <- lapply(dl_naip_IR, rast)
naip_imagery_NC <- lapply(dl_naip_NC, rast)

target_counties <- target_counties[match(dl_naip_tiles, target_counties$COUNTYFP),]
dl_naip_NC

names(naip_imagery_IR) <- target_counties$NAME
names(naip_imagery_NC) <- target_counties$NAME

# rm(dl_naip, path, dl_naip_IR, dl_naip_NC, target_counties, dl_naip_tiles)

# we need to transform the CRS of several rasters from UTM zone 13 to zone 12

UFO_extent_12 <- vect(st_transform(UFO_land, 26912))
UFO_extent_13 <- vect(st_transform(UFO_land, 26913))

for (i in c(1:2,5:6)){
  naip_imagery_NC[[i]] <- crop(naip_imagery_NC[[i]],  UFO_extent_13, mask = T) # reduce extent of files
}
for (i in c(3,4,7)){
  naip_imagery_NC[[i]] <- crop(naip_imagery_NC[[i]],  UFO_extent_12, mask = T)
}
for (i in c(1,5,2)){
  naip_imagery_NC[[i]] <- project(naip_imagery_NC[[i]],  y = naip_imagery_NC[[4]],
                              method = 'cubicspline', align = T, threads = 20)
}
naip_imagery_NC[[6]] <- project(naip_imagery_NC[[6]],  y = naip_imagery_NC[[5]],
                              method = 'cubicspline', align = T, threads = 20)

naip_imagery_collection_NC <- sprc(naip_imagery_NC) # make a wide raster of all tiles
UFO_NAIP_NC <- mosaic(naip_imagery_collection_NC) # create a single large product of rasters

plot(UFO_NAIP_NC)

path <- '/media/sagesteppe/ExternalHD/NAIP/'
# dir.create(file.path(path, 'processed'))
fname <- file.path(path, 'processed', 'NC_naip.tif')
#tile_borders <- rast(ncols = 2, nrows = 2, crs = crs(UFO_NAIP_NC), 
#                     xmin = xmin(UFO_NAIP_NC), xmax = xmax(UFO_NAIP_NC), 
#                     ymax = ymax(UFO_NAIP_NC), ymin = ymin(UFO_NAIP_NC))
#makeTiles(UFO_NAIP_NC, tile_borders, fname)
writeRaster(UFO_NAIP_NC, fname)

rm(naip_imagery_collection_IR, naip_imagery_collection_NC, naip_imagery_IR, naip_imagery_NC, i)
```


```{r Import processed NAIP imagery and resample to other products, echo = F, eval = F}
path <- '/media/sagesteppe/ExternalHD/NAIP/processed'
files <- list.files(path)

naip_IR <- files[grep('IR_naip.tif', files)]
naip_NC <- files[grep('NC_naip.tif', files)]

naip_IR <- rast(file.path(path, naip_IR))
naip_NC <- rast(file.path(path, naip_NC))

# now we will resample this product so that it aligns with the existing physiographic products we have. 

dem <- rast(file.path( '../data/processed/',
            list.files(file.path('../data/processed'),
            pattern = "dem.*smooth.*tif$")))

naip_IR <- resample(naip_IR, dem, method = 'cubicspline', threads = 20, 
                    filename = file.path(path, 'IR_naip_resamp.tif'))
naip_NC <- resample(naip_NC, dem, method = 'cubicspline', threads = 20, 
                    filename = file.path(path, 'NC_naip_resamp.tif'))
```

A Gray Level Co-occurrence Matrix (GLCM) was created using the glcm package to create a texture raster layer to aid in classification. Texture bands are, among other properties, capable of indicating the amounts of heterogeneity of habitat types across the landscape. 

```{r Create Texture Raster band, echo = F, eval = F}

library(factoextra)
library(FactoMineR)
library(glcm)
# https://zia207.github.io/geospatial-r-github.io/texture-analysis.html

# we will perform different runs on the natural color and IR bands to develop the GLCM

path <- '/media/reed/ExternalHD/NAIP/processed'
files <- list.files(path, pattern = 'resamp')
stats <- c("mean", "variance", 'homogeneity', 'contrast', 'dissimilarity')

naip_IR_r <- raster::raster(file.path(path, files[grep('IR*', files)]))
naip_NC_r <- raster::raster(file.path(path, files[grep('NC*', files)]))

Sys.time()
glcm.red <- glcm::glcm(naip_IR_r,
                 window = c(5, 5), shift = list(c(0,1), c(1,1), c(1,0), c(1,-1)), 
                 statistics = stats, 
                 min_x = 1, max_x = 255, na_opt = 'ignore', na_val = 0)
Sys.time()

Sys.time()
glcm.colour <- glcm::glcm(naip_NC_r,
                 window = c(5, 5), shift = list(c(0,1), c(1,1), c(1,0), c(1,-1)), 
                 statistics = stats, 
                 min_x = 1, max_x = 255, na_opt = 'ignore', na_val = 0)
Sys.time()

writeRaster(glcm.colour, file.path(path, 'glcm_red_textures.tif'))
writeRaster(glcm.colour, file.path(path, 'glcm_colour_textures.tif'))

glcm.red <- rast(file.path(path, 'glcm_red_textures.tif'))
glcm.colour <- rast(file.path(path, 'glcm_colour_textures.tif'))

rm(naip_IR_r, naip_NC_r)

## we determine which bands contain the most variation using a PCA
all_textures <- c(glcm.red, glcm.colour)
all_textures <- scale(all_textures, center = T) # scale the data before the function
all_textures[is.na(all_textures)] <- 0 # define zero for all missing values

Sys.time()
texture_values <- values(spatSample(all_textures, # this can take up to an hour or so
                                    ((dim(all_textures)[1] * dim(all_textures)[2]) * 0.01), 
                        as.raster=TRUE))
Sys.time()
rf_veg_pca <- prcomp(texture_values)

saveRDS(rf_veg_pca, "../results/stats/veg_pca.rds")
rf_veg_pca <- readRDS("../results/stats/veg_pca.rds")
texture_PC <- predict(all_textures, rf_veg_pca)

fviz_pca_var(rf_veg_pca,
             col.var = "contrib", # Color by contributions to the PC
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE     # Avoid text overlapping
)

summary(rf_veg_pca)
rf_veg_pca[["rotation"]]

# now select and write out bands with considerable influence to variation
texture_PrincComponents <- subset(texture_PrincComponents, c(1:2))
names(texture_PrincComponents) <- paste0('principal_Component', 
                                         rep(1:dim(texture_PrincComponents)[3]))

plot(texture_PrincComponents)
texture_PrincComponents <- mask(texture_PrincComponents, glcm.red)
plot(texture_PrincComponents)

writeRaster(texture_PrincComponents, file.path(path, 'Textures_pca.tif'), overwrite = T)

rm(texture_PrincComponents, all_textures, glcm.red, glcm.colour, texture_values, rf_veg_pca, texture_PC, files, sr)
```

NAIP data were processed to create an NDVI band. NDVI is well suited for identifying sparsely vegetated areas, it may be useful in distinguishing salt desert from all other strata, and help in distinguishing between MMS and PJ. 

```{r create NDVI band, echo = F, eval = F}
# (NIR - Red) / (NIR + Red)

naip_NC <- rast(naip_NC_r)
naip_IR <- rast(naip_IR_r)
rm(naip_IR_r, naip_NC_r)

naip_ndvi <- (naip_IR[[1]] - naip_NC[[1]]) / (naip_IR[[1]] + naip_NC[[1]])
plot(naip_ndvi) # see the green up at the boundaries with forest service.

writeRaster(naip_ndvi, file.path(path, 'NDVI.tif'), overwrite = T)
```

To create a more equally balanced training data set, all classified AIM points were exported to Google Earth. 150 random points were generated across the focal BLM district and classified in Google Earth via the vegetation ecologist which lead the AIM sampling in 2022. Additional records for each stratum, less Aspen forest, without enough points for balanced sampling were found by the vegetation ecologist and marked via Google Earth. 

```{r Export Points for Manual Classification in Google Earth, echo = F, eval = F}

rndm_VegPts <- st_read(
  file.path(here(), '/data/processed/UFO_Allotments/', 'UFO_Allotments.shp'),
  quiet = T) %>%
  st_union() %>%
  vect()

rndm_VegPts <- rndm_VegPts
  spatSample(size = 150, method="random") %>%
  st_as_sf() %>%
  mutate(ID = 1:n()) %>%
  select(ID) %>%
  st_transform(4326) %>%
  as('Spatial')

rndm_VegPts2 <- rndm_VegPts %>%
  spatSample(size = 250, method="random") %>%
  st_as_sf() %>%
  mutate(ID = 1:n()) %>%
  select(ID) %>%
  st_transform(4326) %>%
  as('Spatial')
 
maptools::kmlPoints(rndm_VegPts, kmlfile = '../data/raw/UFO_Random_Veg_pts.kml',
          name = rndm_VegPts[['ID']], kmlname = 'Random_Veg_pts')
maptools::kmlPoints(rndm_VegPts2, kmlfile = '../data/raw/UFO_Random_Veg_pts2.kml',
          name = rndm_VegPts2[['ID']], kmlname = 'Random_Veg_pts2')

# we will also write a CSV for noting the results quickly.
rndm_VegPts <- rndm_VegPts %>%
  st_as_sf() %>%
  mutate('VegClass' = "",
    'Longitude' = st_coordinates(.)[,1],
    'Latitude' = st_coordinates(.)[,2]) %>%
  st_drop_geometry()
write.csv(rndm_VegPts, file = '../data/raw/UFO_Random_Veg_pts.csv' , row.names = F)
rndm_VegPts2 <- rndm_VegPts2 %>%
  st_as_sf() %>%
  mutate('VegClass' = "",
    'Longitude' = st_coordinates(.)[,1],
    'Latitude' = st_coordinates(.)[,2]) %>%
  st_drop_geometry()
write.csv(rndm_VegPts2, file = '../data/raw/UFO_Random_Veg_pts2.csv' , row.names = F)

rglr_VegPts <- rndm_VegPts %>%
  spatSample(size = 150, method="regular") %>%
  st_as_sf() %>%
  mutate(ID = 1:n()) %>%
  select(ID) %>%
  st_transform(4326) %>%
  as('Spatial')
 
maptools::kmlPoints(rglr_VegPts, kmlfile = '../data/raw/UFO_Regular_Veg_pts.kml',
          name = rglr_VegPts[['ID']], kmlname = 'Regular_Veg_pts')

# get some more. 
rglr_VegPts <- rndm_VegPts %>%
  spatSample(size = 750, method="regular") %>%
  st_as_sf() %>%
  mutate(ID = 1:n()) %>%
  select(ID) %>%
  st_transform(4326) %>%
  as('Spatial')

maptools::kmlPoints(rglr_VegPts, kmlfile = '../data/raw/UFO_Regular_Veg_pts2.kml',
          name = rglr_VegPts[['ID']], kmlname = 'Regular_Veg_pts2')

# we will also write a CSV for noting the results quickly.
rglr_VegPts <- rglr_VegPts %>%
  st_as_sf() %>%
  mutate('VegClass' = "",
    'Longitude' = st_coordinates(.)[,1],
    'Latitude' = st_coordinates(.)[,2]) %>%
  st_drop_geometry()
write.csv(rglr_VegPts, file = '../data/raw/UFO_Regular_Veg_pts2.csv' , row.names = F)


# we will also write out the 2022 plots to KML for manual classification. 
aim2022 <- st_read(file.path(here(), '/data/raw/AIM_Points_2022/', 'AIM_Points_2022.shp'),
        quiet = T) %>% 
  mutate(ID = 1:n()) %>%
  select(ID) %>%
  st_transform(4326) %>%
  as('Spatial')

maptools::kmlPoints(aim2022, kmlfile = '../data/raw/UFO_2022_AIM.kml',
          name = aim2022[['ID']], kmlname = 'UFO_2022_AIM')
aim2022 <- aim2022 %>%
  st_as_sf() %>%
  mutate('VegClass' = "",
    'Longitude' = st_coordinates(.)[,1],
    'Latitude' = st_coordinates(.)[,2]) %>%
  st_drop_geometry()
write.csv(aim2022, file = '../data/raw/UFO_2022_AIM.csv' , row.names = F)

rm(rndm_VegPts, rndm_VegPts2, aim2022)
```


```{r Read in classified points from GE and AIM, echo = F, warning = F, message = F}
random <- file.path('../data/processed/',
  list.files('../data/processed/',  pattern = '*Random*'))
reg <- file.path('../data/processed/',
  list.files('../data/processed/',  pattern = '*Regular*'))

twenty22 <- read.csv('../data/processed/UFO_2022_AIM_CLASSIFIED.csv')
historicVeg <- read.csv('../data/processed/UFO_Veg_monitoring_CLASSIFIED.csv') %>% 
  na_if("")
plot_drawn <- (nrow(twenty22) + nrow(historicVeg))
plot_class <- bind_rows(twenty22, historicVeg) %>% drop_na()

reg_drawn <- do.call(rbind, lapply(reg, function(x) 
  read.csv(x, stringsAsFactors = FALSE)))
reg_pts <- reg_drawn %>% 
  drop_na() %>% 
  filter(VegClass %in% c('AS', 'MC', 'PJ', 'SD', 'SS', 'MMS'))

random_drawn <- do.call(rbind, lapply(random, function(x) 
  read.csv(x, stringsAsFactors = FALSE))) %>% 
  na_if("") 
random_pts <- random_drawn %>% drop_na() 

rm(random, twenty22, historicVeg)
```


To create a more equally balanced training data set, all `r toString(plot_drawn)` AIM and LMF points were exported to Google Earth and `r toString(nrow(plot_class))` were classified. `r toString(nrow(random_drawn))` random points were generated across the focal BLM district and  `r toString(nrow(random_pts))` classified in Google Earth via the vegetation ecologist which lead the AIM sampling in 2022. An additional `r toString(nrow(reg_drawn))` regularly placed plots were drawn across the extent of the field office and `r toString(nrow(reg_pts))` were classified. Unclassified computer generated points were generally those that fell upon a wide road, or were outside BLM Ownership. Unclassified AIM/LMF points were LMF points which must have represented the revisitation of a single plot. 

Classified plots were randomly sampled to ensure an equal number of points per stratum, less Aspen and Mixed Conifer.

```{r buffer points from GE and AIM , echo = F}

p <- file.path(here::here(), 'data/processed')

reg_pts <-  reg_pts %>% 
  st_as_sf(coords = c("Longitude", "Latitude"), crs = 4326) %>% 
  mutate(Type = 'Regular', .after = 'ID') %>% 
  mutate(ID = as.character(ID)) %>% 
  st_transform(26912) %>% 
  st_buffer(30) 

random_pts <- random_pts %>% 
  st_as_sf(coords = c("Longitude", "Latitude"), crs = 4326) %>% 
  mutate(Type = 'Random2', .after = 'ID') %>% 
  st_transform(26912) %>% 
  st_buffer(30) %>% 
  mutate(ID = as.character(ID)) %>% 
  mutate(across(where(is.character), ~na_if(., ""))) %>%
  filter(VegClass %in% c('PJ', 'SD', 'SS', 'MMS'))

veg_pts <- plot_class %>% 
  st_as_sf(coords = c("Longitude", "Latitude"), crs = 4326) %>% 
  mutate(Type = 'Stratified', .after = 'ID') %>% 
  st_transform(26912) %>% 
  st_buffer(30) %>% 
  mutate(ID = as.character(ID))

# AIM DATA post K-Means is read in here
#veg_pts <- st_read(file.path(p, '/reclassified_AIM/reclassified_AIM.shp'), quiet = T) %>% 
#  st_transform(26912) %>%  # these alreday buffered by type. 
#  rename(ID = PlotKey, Type = Plot, VegClass = Veg_type) %>% 
#  bind_rows(., computer_pts) %>% 
#  drop_na() %>% 
#  vect()

# alt route use the manually classified
veg_pts <- bind_rows(veg_pts, random_pts, reg_pts) %>% 
  as(., "Spatial") %>% 
  vect()

rm(reg_pts, random_pts, plot_drawn, random_drawn, reg_drawn)
```

https://valentinitnelav.github.io/satellite-image-classification-r/

```{r Import all Geographic Data and extract occurrences to points, eval = F}

UFO_land <- st_read(
  paste0(here(), '/data/processed/UFO_Allotments/', 'UFO_Allotments.shp'),
  quiet = T) %>% 
  st_transform(4269) %>% 
  st_union() %>% 
  st_cast('POLYGON') %>% 
  st_as_sf() %>% 
  st_make_valid() %>% 
  st_transform(26912) %>% 
  vect()

path <- '/media/sagesteppe/ExternalHD/NAIP/processed'
files <- list.files(path)
files
naip_NC <- rast(file.path(
  path, files[grep('NC_naip_resamp.tif', files)]))
naip_IR <- rast(file.path(
  path, files[grep('IR_naip_resamp.tif', files)]))[[1]]
NDVI <- rast(file.path(
  path, files[grep('NDVI.tif', files)]))

texture <- rast(file.path(
  path, files[grep('Textures_pca.tif', files)]))
texture <- resample(texture, naip_NC, method = 'cubicspline')

PhysioPath <- '/media/sagesteppe/ExternalHD/AIM_Field_rasters'

DEM <- rast(file.path(PhysioPath,
            list.files(PhysioPath,
            pattern = "dem.*smooth.*tif$")))
DEM <- crop(DEM,  UFO_land, mask = T)
DEM <- resample(DEM, naip_NC, method = 'cubicspline')

slope <- rast(file.path(PhysioPath,
            list.files(PhysioPath,
            pattern = "slope*")))
slope <- terra::project(slope,  y = DEM, method = 'cubicspline', align = T)
slope <- crop(slope,  UFO_land, mask = T)
slope <- resample(slope, naip_NC, method = 'cubicspline')

predictors <- c(naip_NC, naip_IR, NDVI, texture, DEM, slope)
names(predictors) <- c('NAIP_red', 'NAIP_green', 'NAIP_blue', 'NAIP_IR', 'NDVI', 
                       'GLCM_PC1', 'GLCM_PC2', 'DEM', 'Slope')

rm(naip_NC, texture, DEM, slope, PhysioPath, UFO_land, files, naip_IR, NDVI, path)
```

```{r set random forest model parameters proportion, echo  = F}
train_prop <- 0.7
mTry <- 4
nTT <- 1000
sF <- 1.5
I <- 0.01
```

```{r Extract Predictor Variables to Points, message = F, warning = 'hide', eval = F}
library(caret)
library(parallel)
library(doParallel)
library(randomForest)

veg_pts <- project(veg_pts, crs(predictors))
VegClass <- extract(predictors, veg_pts, method = 'simple', touches = F, fun = mean )#,
                  #  weights = T) # note weights work on Lightscape, but not parkland. 
VegClass <- cbind(as.data.frame(veg_pts), VegClass[,2:ncol(VegClass)])
VegClass <- VegClass[complete.cases(VegClass),]
VegClass <- cbind(VegClass[,4:ncol(VegClass)], 'class' = VegClass[,3])
VegClass$class <- as.factor(VegClass$class)

split_obs <- createDataPartition(VegClass$class,
                                 p = train_prop, # percentage of data as training
                                 list = FALSE)
train <- VegClass[split_obs,]
test <- VegClass[-split_obs,]
vp <- st_as_sf(veg_pts)
testOriginal <- vp[-split_obs,]

mainDir <- '../data/processed/'
subDir <- 'StratTest'

ifelse(!dir.exists(file.path(mainDir, subDir)), dir.create(file.path(mainDir, subDir)), FALSE)
st_write(testOriginal, file.path(mainDir, subDir, 'TestSetStratification.shp'), quiet = T)

rm(VegClass, split_obs, testOriginal, vp, mainDir, subDir, testOriginal)
```

The dataset of `r toString(nrow(veg_pts))` classified points were partioned into a `r toString(1-train_prop)` test and training set `r toString(train_prop)` using caret, the dataset was not balanced, see table XX for sample sizes.  

```{r Fit Random Forest Model, warning = F, message = F, eval = F}

opt_mtry <- tuneRF(train, train$class, ntreeTry = nTT,
               stepFactor = sF, improve = I, trace = TRUE, plot = TRUE)

cl <- makeCluster(detectCores()-2)
registerDoParallel(cl)
veg_rf_model <- randomForest(class~., data=train, proximity=TRUE, 
                             ntree = nTT, mtry = mTry)
stopCluster(cl); remove(cl)

saveRDS(veg_rf_model, file = filepath('../results/RandomForest', Sys.Date()))
```

```{r Random Forest Results, echo = F, warning = F, message = F, eval = F}
data.frame(print(importance(veg_rf_model, type = 2))) %>% 
  rownames_to_column('Variable') %>% 
  arrange(-MeanDecreaseGini) %>% 
  knitr::kable()

plot(veg_rf_model)
# generate a confusion matrix to determine accuracy on real data.
test_prediction <- predict(veg_rf_model, test)
confusionMatrix(test_prediction, test$class)

rm(cl, opt_mtry, test_prediction, train_prop, test, train)
```

The number of mtry in the random forest model were tuned using the function tuneRF with the number of trys set to `r toString(nTT)`, a step factor of `r toString(sF)` and a relative minimum improvement in Out of Bag (OOB) error rate set at `r toString(I)`. The random forest model was than trained using `r toString(mTry)` mtry and `r toString(nTT)` trees, all using the RandomForest package. 

```{r remove tree parameters, echo = F}
rm(Mtry, nTT, I, sF)
```

```{r Predict random forest onto raster and smooth it, eval = F}

# predict model onto raster
predict_rf <- terra::predict(object = predictors, model = veg_rf_model, cpkgs = 'randomForest',
                     filename = file.path(p, '/PredictedVegClass.tif'),
                     overwrite = T)

# smooth the raster using focal statistics, we will find the mode in a rolling 
# window and re-assign values based upon that. 
predict_rf_smooth <- focal(predict_rf, w = 5, fun = modal, na.policy= 'omit')
plot(predict_rf_smooth, col = c('#e41a1c', '#377eb8', '#4daf4a', '#984ea3', '#ff7f00','#ffff33'))

predict_rf <- writeRaster(predict_rf_smooth, file.path(here(), '/data/processed/PredictedVegClass-sm.tif'), overwrite = T)
```

The Random Forest classification model was predicted onto a raster surface using the package Terra. This raster was then smooth using focal statistics, with a window of 5 cells, using the mode as the value to return. 

```{r Compare to original stratification}
testOriginal <- st_read('../data/processed/StratTest/TestSetStratification.shp', quiet = T) %>%
  vect()

pstrat <- '/media/sagesteppe/ExternalHD/UFO_AIM_Design_Stratification/processed/'
original_strat <- rast(file.path(pstrat, "UFO_Strata.tif"))

testOriginal <- project(testOriginal, crs(original_strat))
outOrig <- extract(original_strat, testOriginal, method = 'simple')
outOrig <- outOrig[complete.cases(outOrig),]

post_strat <- rast(file.path(here(), '/data/processed/PredictedVegClass-sm.tif'))
testOriginal <- project(testOriginal, crs(post_strat))
outPost <- extract(post_strat, testOriginal, method = 'simple')
outPost <- outPost[complete.cases(outPost),]

Mode <- function(x) {
  ux <- unique(x)
  ux[which.max(tabulate(match(x, ux)))]
}

mdsOrig <- outOrig %>%
  group_by(ID) %>% # these are the original values. 
  summarise(OriginalCover = Mode(BPS_CODE))

mdsPost <- outPost %>% 
  group_by(ID) %>% 
  summarise(RestratifiedCover = Mode(lyr1))

inner_join(mdsOrig, mdsPost, by = 'ID')

rm(testOriginal, mdsOrig, mdsPost, Mode, post_strat, outPost, outOrig, original_strat)
```

# Comparision of New and Old vegetation classification models. 

```{r make waffle charts of changes in vegetation, echo = F,  out.width="50%", fig.cap = "Changes in Estimated Land Cover between the initial stratification and post-stratification"}
library(waffle)
library(tidyverse)
library(cowplot)

strata_pal <- setNames(
  c('#4A5A28', '#ADB1B9', '#CEB88E', '#574039', '#B64841',
    '#1357a6', '#1B1212', '#F9E076', '#39993A', '#00688B'),
  c('PJ', 'SS', 'SD', 'MMS', 'AS', 'RI', 'OT', 'GR', 'PP', 'MC')
)

# original land cover of sample design

p <- '/media/sagesteppe/ExternalHD/UFO_AIM_Design_Stratification'
initialGAP <- read.csv(file.path(p, 'raw', 'lookupTable.txt'))

reprocessedGAP <- read.csv(file.path(p, 'processed', 'UFO_strata_areas.csv')) %>% 
  mutate(Percent = round((Cells/sum(Cells) ) *100)) %>% 
  mutate(Code = case_when(
    Stratum  ==  'Aspen' ~ 'AS', 
    Stratum  ==  'Grassland' ~ 'GR', 
    Stratum  ==  'Mixed Conifer' ~  'MC', 
    Stratum  ==  'Mixed Mountain Shrub' ~ 'MMS', 
    Stratum  ==  'Other' ~ 'OT', 
    Stratum  ==  'Pinion Juniper Woodland' ~ 'PJ', 
    Stratum  ==  'Ponderosa Pine' ~ 'PP',
    Stratum  == 'Riparian' ~ 'RI',
    Stratum  == 'Sagebrush' ~ 'SS',
    Stratum  == 'Salt Desert' ~ 'SD'
    )) %>% 
  arrange(-Percent)

strata_pal <- strata_pal[order(match(names(strata_pal),reprocessedGAP$Code))]

strata_waffle <- ggplot(reprocessedGAP, aes(fill = Code, values = Percent)) + 
  geom_waffle(color = 'white') + 
  scale_fill_manual(name = 'Statum',
                    values = strata_pal, 
                    labels = names(strata_pal)) + 
  coord_equal() + 
  theme_void() + 
  labs(title = 'initial stratification')  +
  guides(fill=guide_legend(ncol=2)) +
  theme(plot.title = element_text(hjust = 0.5), 
        legend.title.align = 0.5)

legend <- get_legend(strata_waffle)
strata_waffle <- strata_waffle + theme(legend.position='none')

# now a waffle of what percent habitat plots were located actually IN ??

veg_pts <- veg_pts %>% 
  st_as_sf() %>% 
  st_drop_geometry() %>% 
  filter(Type != 'Stratified') %>% 
  group_by(VegClass) %>% 
  count() %>% 
  ungroup() %>% 
  mutate(Percent = round((n/sum(n))*100 ))  %>% 
  arrange(-Percent)

strata_pal <- strata_pal[order(match(names(strata_pal),veg_pts$VegClass))]
strata_pal3 <- strata_pal[1:nrow(veg_pts)]

random_waffle <- ggplot(veg_pts, aes(fill = VegClass, values = Percent)) + 
  geom_waffle(color = 'white') + 
  scale_fill_manual(name = 'Statum',
                    values = strata_pal3, 
                    labels = names(strata_pal3)) + 
  coord_equal() + 
  theme_void() + 
  theme(legend.position="none") +
  labs(title = 'human classification')  +
  theme(plot.title = element_text(hjust = 0.5))

#  a waffle of what percent habitats exist in UFO based on reclassification

reclassified <- rast(file.path(here(), 'data/processed/PredictedVegClass.tif'))
#plot(reclassified, col = c('#e41a1c', '#377eb8', '#4daf4a', '#984ea3', '#ff7f00','#ffff33'))
area <- values(reclassified)
area <- area[!is.na(area)] # 4 SS, # 3 SD, 2 PJ, 1 MMS
area <- aggregate(area, list(num=area), length)

ltable <- data.frame(
  num = c(1, 2, 3, 4, 5, 6), 
  Stratum = c('AS', 'MC', 'MMS', 'PJ', 'SD', 'SS')
) 

vegclass <- area %>% 
  inner_join(., ltable, 
            by = 'num') %>% 
  select(Cells = x, RasterValue = num, Stratum) %>% 
  mutate(Percent = round((Cells/sum(Cells) ) *100)) %>% 
  arrange(-Percent)

strata_pal <- strata_pal[order(match(names(strata_pal),vegclass$Code))]
strata_pal2 <- strata_pal[1:nrow(vegclass)]

reclass_waffle <- ggplot(vegclass, aes(fill = Stratum, values = Percent)) + 
  geom_waffle(color = 'white') + 
  scale_fill_manual(name = 'Statum',
                    values = strata_pal2, 
                    labels = names(strata_pal2)) + 
  coord_equal() + 
  theme_void() + 
  theme(legend.position="none") + 
  labs(title = 're-modelled classification')  +
  theme(plot.title = element_text(hjust = 0.5))

plot_col <- plot_grid(strata_waffle, random_waffle,
                      reclass_waffle, legend, ncol = 1, rel_widths = c(1,1,1,0.75),
                      rel_heights = c(1,1,1,0.75))

title <- ggdraw() + 
  draw_label(
    "Percent Land Cover",
    fontface = 'bold',
    x = 0,
    hjust = 0
  ) + theme(plot.margin = ggplot2::margin(0, 0, 0, 3.5,  "cm"))

plot_grid(
  title, plot_col,
  ncol = 1,
  # rel_heights values control vertical title margins
  rel_heights = c(0.1, 1) 
)

rm(strata_pal2, strata_pal3, random_waffle, reclass_waffle, legend, plot_col)
```


```{r compare values between rasters to create flow chart, eval = F}
# first match the resolutions of these products, we will resample the coarser original
# to the finer remapped classification. 
original_strat <- rast(file.path(p, 'processed', 'UFO_Strata.tif'))
original_strat <- project(original_strat, crs(reclassified), method = 'near')
orig_strat_resamp <- resample(original_strat, reclassified, method = 'near')
orig_strat_resamp <- mask(orig_strat_resamp, reclassified)
rm(original_strat)
area <- values(orig_strat_resamp)
area <- area[!is.na(area)] 
area <- aggregate(area, list(num=area), length)
area <- area %>% 
  inner_join(., reprocessedGAP %>% select(RasterValue, Code), 
            by = c('num' = 'RasterValue')) %>% 
  rename(Cells = x)
# do !!!NOT!!! try this on gov't computer, reach out to reed (sagesteppe) and he can run it!!!!!

r <- rast(list(orig_strat_resamp, reclassified))
rvals <- as.matrix(r, na.rm = T)
rvals <- rvals[complete.cases(rvals),]
rvals <- data.frame(rvals) %>% 
  group_by(lyr1) %>% 
  count(BPS_CODE) %>% 
  rename(Reclassified = lyr1,
        Original= BPS_CODE)

p1 <- '/media/sagesteppe/ExternalHD/plot_post_stratification/data/processed'
write.csv(rvals, file.path(p1, 'Extracted_raster_values.csv'), row.names = F)
write.csv(area, file.path(p1, 'Count_OriginalStrat_raster_values.csv'), row.names = F)
rm(d, original_strat, reclassified)
```

```{r reimport data for showing flow from veg classes, fig.cap="This diagram shows how raster cells in the UFO are redistributed from the original sample design, to the the reclassified spatial product for the sample design"}
library(circlize)
p1 <- '/media/sagesteppe/ExternalHD/plot_post_stratification/data/processed'
rvals <- read.csv(file.path(p1, 'Extracted_raster_values.csv'))
area <- read.csv(file.path(p1, 'Count_OriginalStrat_raster_values.csv'))

rvals <- rvals %>% 
  mutate(n = round( n/100000, 1)) %>% 
  pivot_wider(names_from = 'Reclassified', values_from = 'n') %>% 
  column_to_rownames('Original') %>% # for circle chart. 
  as.matrix()

colnames(rvals) <- paste0('to ', ltable$Stratum)
rownames(rvals) <- reprocessedGAP %>% 
  arrange(RasterValue) %>% 
  pull(Code)
sp2 <- strata_pal # create a palette to mark the colors in both ends
names(sp2) <- paste0('to ', names(strata_pal))
all_pals<- c(strata_pal, sp2)
chordDiagram(rvals, transparency = 0.5, directional = 1, 
             grid.col = all_pals, diffHeight  = -0.04)
```


The initial AIM sample design was based upon a stratification which included `r` communities. This design was based on a manual reclassification of the GAP/LANDFIRE National Terrestrial Ecosystems 2011 data set. 


# Citations

```{r Citations, echo = F}
c("terra", "glcm", "RStoolbox", "randomForest", "caret", "parallel", "doParallel") %>%
  map(citation) %>%
  print(style = "text")

```

